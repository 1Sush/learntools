{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Set Up\n",
    "\n",
    "Today you will create partial dependence plots with data from the [Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction) competition.\n",
    "\n",
    "You will again start with code to do the basic loading, review and model-building.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-21 04:30:42.0000001</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-09 07:51:00.000000135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-11-20 20:35:00.0000001</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2012-11-20 20:35:00 UTC</td>\n",
       "      <td>-73.980002</td>\n",
       "      <td>40.751662</td>\n",
       "      <td>-73.973802</td>\n",
       "      <td>40.764842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-01-04 17:22:00.00000081</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2012-01-04 17:22:00 UTC</td>\n",
       "      <td>-73.951300</td>\n",
       "      <td>40.774138</td>\n",
       "      <td>-73.990095</td>\n",
       "      <td>40.751048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount          pickup_datetime  \\\n",
       "2   2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n",
       "3    2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n",
       "4  2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n",
       "6    2012-11-20 20:35:00.0000001          7.5  2012-11-20 20:35:00 UTC   \n",
       "7   2012-01-04 17:22:00.00000081         16.5  2012-01-04 17:22:00 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "2        -73.982738        40.761270         -73.991242         40.750562   \n",
       "3        -73.987130        40.733143         -73.991567         40.758092   \n",
       "4        -73.968095        40.768008         -73.956655         40.783762   \n",
       "6        -73.980002        40.751662         -73.973802         40.764842   \n",
       "7        -73.951300        40.774138         -73.990095         40.751048   \n",
       "\n",
       "   passenger_count  \n",
       "2                2  \n",
       "3                1  \n",
       "4                1  \n",
       "6                1  \n",
       "7                1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Environment Set-Up for feedback system.\n",
    "import sys\n",
    "sys.path.append('../input/ml-insights-tools')\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from ex3 import *\n",
    "print(\"Setup Complete\")\n",
    "\n",
    "# Data manipulation code below here\n",
    "data = pd.read_csv('../input/new-york-city-taxi-fare-prediction/train.csv', nrows=50000)\n",
    "\n",
    "# Remove data with extreme outlier coordinates or negative fares\n",
    "data = data.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +\n",
    "                  'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +\n",
    "                  'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +\n",
    "                  'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +\n",
    "                  'fare_amount > 0'\n",
    "                  )\n",
    "\n",
    "y = data.fare_amount\n",
    "\n",
    "base_features = ['pickup_longitude',\n",
    "                 'pickup_latitude',\n",
    "                 'dropoff_longitude',\n",
    "                 'dropoff_latitude']\n",
    "\n",
    "X = data[base_features]\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "first_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y)\n",
    "print(\"Data sample:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Here is the code to plot the partial dependence plot for pickup_longitude.  Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "feat_name = 'pickup_longitude'\n",
    "pdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does the partial dependence plot have this U-shape?\n",
    "\n",
    "Does your explanation suggest what shape to expect in the partial plots for the other features?\n",
    "\n",
    "Create the other partial plots below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat_name in base_features:\n",
    "    pdp_dist = _\n",
    "    _\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the shapes match your expectations for what shapes they would have? Can you explain the shape now that you've seen them? \n",
    "\n",
    "Uncomment the following line to check your intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Now you will run a 2D partial dependence plot.  As a reminder, here is the code from the tutorial.  \n",
    "\n",
    "```\n",
    "inter1  =  pdp.pdp_interact(model=my_model, dataset=val_X, model_features=feature_names, features=['Goal Scored', 'Distance Covered (Kms)'])\n",
    "\n",
    "pdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=['Goal Scored', 'Distance Covered (Kms)'], plot_type='contour')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "What do you expect a similar interaction plot with `pickup_longitude` and `dropoff_longitude` to look like?  After you've thought about it, create a 2D plot for these two features.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "\n",
    "# Then uncomment the following line to check your code\n",
    "# q2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like a hint or the solution, uncomment the right line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2.hint()\n",
    "# q2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Consider a ride starting at longitude -73.92 and ending at longitude -74. Using the graph from the last question, estimate how much money the rider would have saved if they'd started the ride at longitude -73.98 instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savings_from_shorter_trip = _\n",
    "\n",
    "# Uncomment the line below to check your answer\n",
    "# q4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a solution or hint, uncomment the appropriate line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q4.hint()\n",
    "# q4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "In the PDP's you've seen so far, location features have primarily served as a proxy to capture distance traveled. In the permutation importance lessons, you added the features `abs_lon_change` and `abs_lat_change` as a more direct measure of distance.\n",
    "\n",
    "Create these features again here. You only need to fill in the top two lines.  Then run the following cell.  **After you run it, identify the most important difference between this partial dependence plot and the one you got above without the absolute value features.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new features\n",
    "data['abs_lon_change'] = _\n",
    "data['abs_lat_change'] = _\n",
    "\n",
    "features_2  = ['pickup_longitude',\n",
    "               'pickup_latitude',\n",
    "               'dropoff_longitude',\n",
    "               'dropoff_latitude',\n",
    "               'abs_lat_change',\n",
    "               'abs_lon_change']\n",
    "\n",
    "X = data[features_2]\n",
    "new_train_X, new_val_X, new_train_y, new_val_y = train_test_split(X, y, random_state=1)\n",
    "second_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(new_train_X, new_train_y)\n",
    "\n",
    "feat_name = 'pickup_longitude'\n",
    "pdp_dist = pdp.pdp_isolate(model=second_model, dataset=new_val_X, model_features=features_2, feature=feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()\n",
    "\n",
    "# uncomment the line below to check your answer\n",
    "# q4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the lines below to see a hint or the solution (including an explanation of the important difference betweent the plots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q4.hint()\n",
    "# q4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Consider a scenario where you have only 2 predictive features, which we will call `feat_A` and `feat_B`. Both features have minimum values of -1 and maximum values of 1.  The partial dependence plot for `feat_A` increases steeply over its whole range, whereas the partial dependence plot for feature B increases at a slower rate (less steeply) over its whole range.\n",
    "\n",
    "Does this guarantee that `feat_A` will have a higher permutation importance than `feat_B`.  Why or why not?\n",
    "\n",
    "After you've thought about it, uncomment the line below for a hint or the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q5.hint()\n",
    "# q5.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Create a dataset with the following characteristics:\n",
    "- There are 2 predictive features and a target\n",
    "- Each predictive feature has a range from -2 to 2.\n",
    "- The PDP of your first feature (called `X1`) has a positive slope from [-1,1], and a negative slope everywhere else when run in a decision tree model.\n",
    "\n",
    "*Note: You are supplied the code to create the predictive features, and you only need to create y*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "# Create array holding predictive feature\n",
    "X1 = 4 * rand(n_samples) - 2\n",
    "X2 = 4 * rand(n_samples) - 2\n",
    "# Create y. you should have X in the expression for y\n",
    "y = _\n",
    "\n",
    "\n",
    "# create dataframe because pdp_isolate expects a dataFrame as an argument\n",
    "my_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
    "predictors_df = my_df.drop(['y'], axis=1)\n",
    "\n",
    "my_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n",
    "\n",
    "\n",
    "# Uncomment the line below to check your answer\n",
    "# q6.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the lines below for a hint or solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q6.hint()\n",
    "# q6.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Create a dataset with 2 features and a target, such that the pdp of the first feature is flat, but its permutation importance is high.  We will use a RandomForest for the model.\n",
    "\n",
    "*Note: You only need to supply the lines that create the variables X1, X2 and y. The code to check your data is provided*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "n_samples = 10000\n",
    "\n",
    "# Create array holding predictive feature\n",
    "X1 = _\n",
    "X2 = _\n",
    "# Create y. you should have X in the expression for y\n",
    "y = _\n",
    "\n",
    "\n",
    "# create dataframe because pdp_isolate expects a dataFrame as an argument\n",
    "my_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
    "predictors_df = my_df.drop(['y'], axis=1)\n",
    "\n",
    "my_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n",
    "\n",
    "\n",
    "pdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, 'X1')\n",
    "plt.show()\n",
    "\n",
    "perm = PermutationImportance(my_model).fit(predictors_df, my_df.y)\n",
    "\n",
    "# show the weights for the permutation importance you just calculated\n",
    "eli5.show_weights(perm, feature_names = ['X1', 'X2'])\n",
    "\n",
    "# Uncomment the following line to check your answer.\n",
    "# q7.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines for the hint or solution\n",
    "# q7.hint()\n",
    "# q7.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats\n",
    "\n",
    "Partial dependence plots can be really interesting. We have a [discussion thread](https://www.kaggle.com/learn-forum/65782) to talk about what real-world topics or questions you'd be curious to see addressed with partial dependence plots. \n",
    "\n",
    "Next up is **SHAP values** which help you understand the logic for each individual prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
