{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (t-SNE)\n",
    "\n",
    "One practical application of visualizing trained embeddings with t-SNE is understanding what information about the embedded entities our model has (and hasn't) learned. This can give us some intuition about how our model works, what latent features it thinks are useful, whether adding certain additional data explicitly might improve the model's accuracy, and so on.\n",
    "\n",
    "In the [lesson](#$TUTORIAL_URL(4)$), we briefly explored the question of whether our embeddings were sensitive to genre. In this exercise, we'll see if we can identify patterns in our 2-d embedding space when we group or filter by some other movie metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, run the code cell below to import the necessary libraries, and load a copy of the t-SNE mapping we learned in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: setup code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Release year\n",
    "\n",
    "Complete the code cell below to create a scatter-plot of our movies where the color of each point varies according to its year of release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any patterns? Any exceptions to that pattern? If you're curious, you can try using the `plot_region` function to zoom in on an area of the embedding space and apply text labels to the points there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Average rating\n",
    "\n",
    "This is a very salient question for our problem of predicting user-assigned ratings. Does a movie's \"goodness\" or \"badness\", as measured by its average user rating, manifest in its embedding? Complete the code cell below to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**: Some movies are divisive - you either love them, or you hate them. Is this reflected in our embeddings? You'll have to come up with a way to calculate a measure of how 'spread out' the user ratings are for each movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Number of ratings\n",
    "\n",
    "Do our embeddings reflect the number of ratings we have in the dataset for each movie? We might think of this as a proxy for how popular or obscure a movie is. Complete the code cell below to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. (Bonus) Going further afield\n",
    "\n",
    "If you're feeling ambitious, try searching for another Kaggle movie dataset and visualizing one or more variables you find there. You'll need to do a join with our MovieLens data on title.\n",
    "\n",
    "For example, [imdb-data](https://www.kaggle.com/PromptCloudHQ/imdb-data) has some interesting features we're missing including box office revenue, runtime, and director.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it for t-SNE. Though, if you're so inclined, I encourage you to do your own exploration of the embedding space using the helper functions defined at the top of the notebook (or defining your own). It's a lot of fun! Well, at least if you're a movie buff. And if you discover an interesting pattern, or build a visualization you're especially proud of, do share it on [the forums](TODO)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`</exercise>`\n",
    "\n",
    "# Scratch\n",
    "\n",
    "I think it's a lot of fun playing with the exploration methods shown in the tut (zooming in on the neighbourhood around a particular movie, zooming in on and identifying clusters, coloring by metadata). Would like this exercise to be somewhat edifying and challenging, but would also like to encourage them to just explore a bit and have fun. Same with lesson/ex.\n",
    "\n",
    "- try on another dataset (even on non-embeddings - i.e. on some high-dimensional data directly? Or is that getting too off-topic?)\n",
    "    - fashion mnist? https://www.kaggle.com/zalando-research/fashionmnist\n",
    "    - load pretrained word embeddings and do T-SNE on them? Though I think this is less fun than movies, in terms of just exploring the mapping and correlating with auxiliary variables.\n",
    "- experiment with perplexity\n",
    "    - this is already pretty well-covered in the tutorial. Maybe could just snip that section of tutorial, and turn it into exercise problems.\n",
    "- exploring and doing variants on the vizualizations we did in the tutorial. zooming in on a region (possibly centred on some specific movie), coloring points by some auxiliary metric.\n",
    "    - visualize year\n",
    "- join with a dataset like https://www.kaggle.com/PromptCloudHQ/imdb-data to get aux variables\n",
    "- training on subset pitfall\n",
    "- question: are our embeddings attuned to 'goodness'/'badness'? Do a visualization experiment to find out.\n",
    "    - also, does it depend on whether we train w/ biases? That's a super interesting question.\n",
    "- it would be fun to have an exercise that has them freeze and visualize the 2-d embeddings at intervals during training, to see how the embs evolve. But sklearn's implementation just straight up doesn't allow this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
