{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (Matrix Factorization)\n",
    "\n",
    "In this lesson, we'll reuse the model we trained in [the tutorial](#$TUTORIAL_URL(2)$). To get started, run the setup cell below to import the libraries we'll be using, load our data into Dataframes, and load a serialized version of the model we trained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "\n",
    "input_dir = '../input/movielens_preprocessed'\n",
    "# XXX: Remember to shuffle if this ends up being used to train anything\n",
    "df = pd.read_csv(os.path.join(input_dir, 'rating.csv'), usecols=['userId', 'movieId', 'rating', 'y'])\n",
    "#movies_df = pd.read_csv(os.path.join(input_dir, 'movie.csv'), usecols=['movieId', 'title', 'year']).set_index('movieId', drop=False)\n",
    "movies = movies_df = pd.read_csv(os.path.join(input_dir, 'movie.csv'), index_col=0)\n",
    "\n",
    "# TODO: suppress warning\n",
    "model = keras.models.load_model('factorization_model.h5')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generating Recommendations\n",
    "\n",
    "\n",
    "#### DB: I'm concerned that the user is learning more about how to use recommender systems in parts 1-2 below, rather than about factorization (which is nominally the topic of this lesson).\n",
    "\n",
    "\n",
    "At the end of [the first lesson where we built an embedding model](#$TUTORIAL_URL(1)$), I showed how we could use our model to predict the ratings a particular user would give to some set of movies.\n",
    "\n",
    "For reference, here's a (slightly modified) copy of that code where we calculated predicted ratings for 7 specific movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>366</td>\n",
       "      <td>Naked Gun 33 1/3: The Final Insult</td>\n",
       "      <td>3.761633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1305</td>\n",
       "      <td>The Blob</td>\n",
       "      <td>3.392891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>2444</td>\n",
       "      <td>Planet of the Apes</td>\n",
       "      <td>3.958446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>3775</td>\n",
       "      <td>The Naked Gun: From the Files of Police Squad!</td>\n",
       "      <td>4.945270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>3776</td>\n",
       "      <td>The Naked Gun 2 1/2: The Smell of Fear</td>\n",
       "      <td>4.457911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                           title  \\\n",
       "366       366              Naked Gun 33 1/3: The Final Insult   \n",
       "1305     1305                                        The Blob   \n",
       "2444     2444                              Planet of the Apes   \n",
       "3775     3775  The Naked Gun: From the Files of Police Squad!   \n",
       "3776     3776          The Naked Gun 2 1/2: The Smell of Fear   \n",
       "\n",
       "      predicted_rating  \n",
       "366           3.761633  \n",
       "1305          3.392891  \n",
       "2444          3.958446  \n",
       "3775          4.945270  \n",
       "3776          4.457911  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = 26556\n",
    "candidate_movies = movies[\n",
    "    movies.title.str.contains('Naked Gun')\n",
    "    | ((movies.title == 'Planet of the Apes') & (movies.year==1968))\n",
    "    | ((movies.title == 'The Blob') & (movies.year==1958))\n",
    "    | (movies.title == 'The Sisterhood of the Traveling Pants')\n",
    "    | (movies.title == 'Lilo & Stitch')\n",
    "].copy()\n",
    "\n",
    "preds = model.predict([\n",
    "    [uid] * len(candidate_movies), # User ids \n",
    "    candidate_movies.index, # Movie ids\n",
    "])\n",
    "# Because our model was trained on a 'centered' version of rating (subtracting the mean, so that\n",
    "# the target variable had mean 0), to get the predicted star rating on the original scale, we need\n",
    "# to add the mean back in.\n",
    "row0 = df.iloc[0]\n",
    "offset = row0.rating - row0.y\n",
    "candidate_movies['predicted_rating'] = preds + offset\n",
    "candidate_movies.head()[ ['movieId', 'title', 'predicted_rating'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we're interested in the somewhat more open-ended problem of **generating recommendations**. i.e. given some user ID and some number `k`, we need to generate a list of `k` movies we think the user will enjoy.\n",
    "\n",
    "The most straightforward way to do this would be to calculate the predicted rating this user would assign for *every movie in the dataset*, then take the movies with the `k` highest predictions.\n",
    "\n",
    "In the code cell below, write code to create a variable `reccs` containing the 5 movies with the highest predicted rating for the user with userId 26556. `reccs` should be a DataFrame with a `movieId` column (it can also have any other additional columns you'd like).\n",
    "\n",
    "**TODO: Maybe have them fill in the body of a function for generating recommendations instead? That way, it would be easy for them to reuse it later on to get reccs for other models that we load (in part 5). Or try it on other users. fn would take model, k, and uid as inputs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 26556\n",
    "\n",
    "# 1. Create a list/array containing all movie ids (from the movies dataframe)\n",
    "\n",
    "# 2. Call model.predict() on a list/array with repeated copies of uid, and the sequence you created in step 1\n",
    "\n",
    "# 3. Get the movieIds associated with the 5 highest values returned in step 2. The easiest thing may be to\n",
    "#    add a 'predicted_rating' column to the movies dataframe (or a copy of it), then sort on that column.\n",
    "\n",
    "# 4. Assign assign the result of 3 to reccs!\n",
    "reccs = []\n",
    "#q1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId_orig</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21770</th>\n",
       "      <td>21770</td>\n",
       "      <td>McKenna Shoots for the Stars</td>\n",
       "      <td>Children|Drama</td>\n",
       "      <td>105563</td>\n",
       "      <td>McKenna Shoots for the Stars (2012)</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>4.250</td>\n",
       "      <td>8.314218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25793</th>\n",
       "      <td>25793</td>\n",
       "      <td>Babette Goes to War</td>\n",
       "      <td>Comedy|War</td>\n",
       "      <td>126126</td>\n",
       "      <td>Babette Goes to War (1959)</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>7.968132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25794</th>\n",
       "      <td>25794</td>\n",
       "      <td>Belle comme la femme d'un autre</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>126128</td>\n",
       "      <td>Belle comme la femme d'un autre (2014)</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.963298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26329</th>\n",
       "      <td>26329</td>\n",
       "      <td>Sense &amp; Sensibility</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>129032</td>\n",
       "      <td>Sense &amp; Sensibility (2008)</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>4.125</td>\n",
       "      <td>7.767604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25823</th>\n",
       "      <td>25823</td>\n",
       "      <td>The Sex and Violence Family Hour</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>126186</td>\n",
       "      <td>The Sex and Violence Family Hour (1983)</td>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>7.720160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                             title              genres  \\\n",
       "21770    21770      McKenna Shoots for the Stars      Children|Drama   \n",
       "25793    25793               Babette Goes to War          Comedy|War   \n",
       "25794    25794   Belle comme la femme d'un autre              Comedy   \n",
       "26329    26329               Sense & Sensibility       Drama|Romance   \n",
       "25823    25823  The Sex and Violence Family Hour  (no genres listed)   \n",
       "\n",
       "       movieId_orig                                      key  year  n_ratings  \\\n",
       "21770        105563      McKenna Shoots for the Stars (2012)  2012          2   \n",
       "25793        126126               Babette Goes to War (1959)  1959          1   \n",
       "25794        126128   Belle comme la femme d'un autre (2014)  2014          1   \n",
       "26329        129032               Sense & Sensibility (2008)  2008          4   \n",
       "25823        126186  The Sex and Violence Family Hour (1983)  1983          1   \n",
       "\n",
       "       mean_rating  predicted_rating  \n",
       "21770        4.250          8.314218  \n",
       "25793        1.500          7.968132  \n",
       "25794        1.000          7.963298  \n",
       "26329        4.125          7.767604  \n",
       "25823        1.500          7.720160  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1.solution()\n",
    "uid = 26556\n",
    "all_movie_ids = df.movieId.unique()\n",
    "preds = model.predict([\n",
    "    np.repeat(uid, len(all_movie_ids)),\n",
    "    all_movie_ids,\n",
    "])\n",
    "# Add back the offset calculated earlier, to 'uncenter' the ratings, and get back to a [0.5, 5] scale.\n",
    "movies_df.loc[all_movie_ids, 'predicted_rating'] = preds + offset\n",
    "n = 5\n",
    "reccs = movies_df.sort_values(by='predicted_rating', ascending=False).head(n)\n",
    "reccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sanity check\n",
    "\n",
    "Do these recommendations seem sensible? If you'd like a reminder of user 26556's tastes, run the cell below to see all their ratings (in descending order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>y</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26556</td>\n",
       "      <td>2706</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.474504</td>\n",
       "      <td>Airplane II: The Sequel</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1982</td>\n",
       "      <td>4284</td>\n",
       "      <td>3.041351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26556</td>\n",
       "      <td>2705</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.474504</td>\n",
       "      <td>Airplane!</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1980</td>\n",
       "      <td>18866</td>\n",
       "      <td>3.800440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26556</td>\n",
       "      <td>534</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974504</td>\n",
       "      <td>Six Degrees of Separation</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1993</td>\n",
       "      <td>5101</td>\n",
       "      <td>3.708884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26556</td>\n",
       "      <td>2102</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974504</td>\n",
       "      <td>Strangers on a Train</td>\n",
       "      <td>Crime|Drama|Film-Noir|Thriller</td>\n",
       "      <td>1951</td>\n",
       "      <td>5154</td>\n",
       "      <td>4.162029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26556</td>\n",
       "      <td>2863</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974504</td>\n",
       "      <td>Dr. No</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>1962</td>\n",
       "      <td>7183</td>\n",
       "      <td>3.683762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26556</td>\n",
       "      <td>2286</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974504</td>\n",
       "      <td>Fletch</td>\n",
       "      <td>Comedy|Crime|Mystery</td>\n",
       "      <td>1985</td>\n",
       "      <td>6298</td>\n",
       "      <td>3.446007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26556</td>\n",
       "      <td>2216</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974504</td>\n",
       "      <td>History of the World: Part I</td>\n",
       "      <td>Comedy|Musical</td>\n",
       "      <td>1981</td>\n",
       "      <td>4313</td>\n",
       "      <td>3.597246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26556</td>\n",
       "      <td>937</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974504</td>\n",
       "      <td>Mr. Smith Goes to Washington</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1939</td>\n",
       "      <td>5712</td>\n",
       "      <td>4.031262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26556</td>\n",
       "      <td>730</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474504</td>\n",
       "      <td>Spy Hard</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1996</td>\n",
       "      <td>6112</td>\n",
       "      <td>2.741261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26556</td>\n",
       "      <td>916</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474504</td>\n",
       "      <td>To Catch a Thief</td>\n",
       "      <td>Crime|Mystery|Romance|Thriller</td>\n",
       "      <td>1955</td>\n",
       "      <td>4699</td>\n",
       "      <td>4.030083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26556</td>\n",
       "      <td>913</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474504</td>\n",
       "      <td>Notorious</td>\n",
       "      <td>Film-Noir|Romance|Thriller</td>\n",
       "      <td>1946</td>\n",
       "      <td>4932</td>\n",
       "      <td>4.202570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26556</td>\n",
       "      <td>3890</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474504</td>\n",
       "      <td>Diamonds Are Forever</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>1971</td>\n",
       "      <td>4357</td>\n",
       "      <td>3.505437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26556</td>\n",
       "      <td>1414</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.025496</td>\n",
       "      <td>Waiting for Guffman</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1996</td>\n",
       "      <td>5957</td>\n",
       "      <td>3.942294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26556</td>\n",
       "      <td>2907</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.025496</td>\n",
       "      <td>Thunderball</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>1965</td>\n",
       "      <td>4210</td>\n",
       "      <td>3.615259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26556</td>\n",
       "      <td>3414</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.025496</td>\n",
       "      <td>Network</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>1976</td>\n",
       "      <td>5206</td>\n",
       "      <td>4.025415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26556</td>\n",
       "      <td>4917</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.025496</td>\n",
       "      <td>Gosford Park</td>\n",
       "      <td>Comedy|Drama|Mystery</td>\n",
       "      <td>2001</td>\n",
       "      <td>6182</td>\n",
       "      <td>3.627055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26556</td>\n",
       "      <td>1861</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.525496</td>\n",
       "      <td>On the Waterfront</td>\n",
       "      <td>Crime|Drama</td>\n",
       "      <td>1954</td>\n",
       "      <td>5644</td>\n",
       "      <td>4.160674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26556</td>\n",
       "      <td>1082</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-1.025496</td>\n",
       "      <td>A Streetcar Named Desire</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1951</td>\n",
       "      <td>6372</td>\n",
       "      <td>4.008646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26556</td>\n",
       "      <td>3445</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-1.025496</td>\n",
       "      <td>Keeping the Faith</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>2000</td>\n",
       "      <td>4033</td>\n",
       "      <td>3.461719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26556</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.525496</td>\n",
       "      <td>The Day the Earth Stood Still</td>\n",
       "      <td>Drama|Sci-Fi|Thriller</td>\n",
       "      <td>1951</td>\n",
       "      <td>6259</td>\n",
       "      <td>3.934768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>26556</td>\n",
       "      <td>2348</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-3.025496</td>\n",
       "      <td>A Civil Action</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1998</td>\n",
       "      <td>3965</td>\n",
       "      <td>3.335152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating         y                          title  \\\n",
       "0    26556     2706     5.0  1.474504        Airplane II: The Sequel   \n",
       "1    26556     2705     5.0  1.474504                      Airplane!   \n",
       "2    26556      534     4.5  0.974504      Six Degrees of Separation   \n",
       "3    26556     2102     4.5  0.974504           Strangers on a Train   \n",
       "4    26556     2863     4.5  0.974504                         Dr. No   \n",
       "5    26556     2286     4.5  0.974504                         Fletch   \n",
       "6    26556     2216     4.5  0.974504   History of the World: Part I   \n",
       "7    26556      937     4.5  0.974504   Mr. Smith Goes to Washington   \n",
       "8    26556      730     4.0  0.474504                       Spy Hard   \n",
       "9    26556      916     4.0  0.474504               To Catch a Thief   \n",
       "10   26556      913     4.0  0.474504                      Notorious   \n",
       "11   26556     3890     4.0  0.474504           Diamonds Are Forever   \n",
       "12   26556     1414     3.5 -0.025496            Waiting for Guffman   \n",
       "13   26556     2907     3.5 -0.025496                    Thunderball   \n",
       "14   26556     3414     3.5 -0.025496                        Network   \n",
       "15   26556     4917     3.5 -0.025496                   Gosford Park   \n",
       "16   26556     1861     3.0 -0.525496              On the Waterfront   \n",
       "17   26556     1082     2.5 -1.025496       A Streetcar Named Desire   \n",
       "18   26556     3445     2.5 -1.025496              Keeping the Faith   \n",
       "19   26556     1225     2.0 -1.525496  The Day the Earth Stood Still   \n",
       "20   26556     2348     0.5 -3.025496                 A Civil Action   \n",
       "\n",
       "                            genres  year  n_ratings  mean_rating  \n",
       "0                           Comedy  1982       4284     3.041351  \n",
       "1                           Comedy  1980      18866     3.800440  \n",
       "2                            Drama  1993       5101     3.708884  \n",
       "3   Crime|Drama|Film-Noir|Thriller  1951       5154     4.162029  \n",
       "4        Action|Adventure|Thriller  1962       7183     3.683762  \n",
       "5             Comedy|Crime|Mystery  1985       6298     3.446007  \n",
       "6                   Comedy|Musical  1981       4313     3.597246  \n",
       "7                            Drama  1939       5712     4.031262  \n",
       "8                           Comedy  1996       6112     2.741261  \n",
       "9   Crime|Mystery|Romance|Thriller  1955       4699     4.030083  \n",
       "10      Film-Noir|Romance|Thriller  1946       4932     4.202570  \n",
       "11       Action|Adventure|Thriller  1971       4357     3.505437  \n",
       "12                          Comedy  1996       5957     3.942294  \n",
       "13       Action|Adventure|Thriller  1965       4210     3.615259  \n",
       "14                    Comedy|Drama  1976       5206     4.025415  \n",
       "15            Comedy|Drama|Mystery  2001       6182     3.627055  \n",
       "16                     Crime|Drama  1954       5644     4.160674  \n",
       "17                           Drama  1951       6372     4.008646  \n",
       "18            Comedy|Drama|Romance  2000       4033     3.461719  \n",
       "19           Drama|Sci-Fi|Thriller  1951       6259     3.934768  \n",
       "20                           Drama  1998       3965     3.335152  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings = df[df.userId==uid]\n",
    "movie_cols = ['movieId', 'title', 'genres', 'year', 'n_ratings', 'mean_rating']\n",
    "user_ratings.sort_values(by='rating', ascending=False).merge(movies[movie_cols], on='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review our top-recommended movies. Are they good or bad? If they're bad, in what way are they bad? You may also find it interesting to look at:\n",
    "- The metadata associated with the top-recommended movies\n",
    "- The 'least-recommended' movies (the ones with the lowest predicted scores)\n",
    "- The actual predicted rating values.\n",
    "\n",
    "Once you have an opinion, uncomment the cell below to see if we're in agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#q2.solution()`\n",
    "\n",
    "\n",
    "#### DB: I think we should aim for as little text as possible in the exercises.  \n",
    "\n",
    "#### DB: I've watched people using other MOOCs before, and they tend look for the parts that they do... their eyes skip over any text that isn't either specific instructions or code (and in some cases, they seem to skip over that as well.  In that sense, the words are in the way.\n",
    "\n",
    "\n",
    "I'm going to claim that these recommended movies are **bad**. In terms of genre and themes, our top picks seem like poor fits. User 26556 has pretty mature tastes - they like Hitchcock, classic James Bond, and Leslie Nielsen comedies. But our top pick for them, *McKenna Shoots for the Stars*, seems squarely aimed at pre-teen girls.\n",
    "\n",
    "Though I had to google the title to discover that fact. In fact, I didn't recognize any of the films in our top-5 recommendations. And that speaks to the biggest problem with our recommendations: they're **super obscure**. Our top 5 recommendations only have a total of 9 reviews between them in the whole dataset. We barely know anything about these movies - how can we be so confident that user 26556 is going to love them?\n",
    "\n",
    "(You may have noticed another problem, which becomes very obvious when we look at the movies with \n",
    "the highest (or lowest) predicted scores: sometimes our model predicts values outside the allowable\n",
    "range of 0.5-5 stars. For the purposes of recommendation, this is actually no problem: we only care about ranking\n",
    "movies, not about the absolute values of their predicted scores. But this is still an interesting problem\n",
    "to consider. How could we prevent our model from incurring needless errors by making predictions outside\n",
    "the allowable range? Should we? If you have ideas, head over to [this forum thread](TODO) to discuss.)\n",
    "\n",
    "**TODO: Mention how this is a common/important problem when working with sparse, high-cardinality categorical data with heavy tails. We'll encounter similar problems in the next two lessons.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: How are we going to fix this mess?\n",
    "#### DB: I really like this problem.\n",
    "How can we improve the problem with our recommendations that we identified in Part 2? This could involve changing our model's structure, our training procedure, or our procedure.\n",
    "\n",
    "Give it some thought, then uncomment the cell below to compare notes with me. (If you have no idea, that's totally fine!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`q3.solution()`\n",
    "\n",
    "One simple solution would be limiting our recommendations to movies with at least `n` ratings. This feels somewhat inelegant, in that we have to choose some arbitrary cut-off. And any reasonable choice will probably exclude some good recommendations. It would be nice if we could take into account popularity in a 'smoother' way. On the other hand, this is very simple to implement, and we don't even need to re-train our model, so it's worth a shot.\n",
    "\n",
    "If we're willing to train a new model, there's another less hacky approach we can take which might fix our obscure recommendation problem *and* improve our overall accuracy at the same time: regularization. Specifically, putting an L2 weight penalty on our embeddings. I'll talk more about this in part 5 (and show how we would implement it).\n",
    "\n",
    "**TODO: Maybe also mention violation of missing at random assumption. Idea of augmenting training data with missing values from the user-item matrix drawn from a distribution with a lower mean than the avg. rating in the dataset. https://arxiv.org/pdf/1206.5267.pdf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Fixing our obscure recommendation problem (thresholding)\n",
    "\n",
    "Fill in the code cell below to create a variable `popular_reccs` containing our 5 best recommendations for user #26556 limited to movies that have at least 1,000 ratings in the dataset. Take a look at the recommended movies. Did this fix our problem? Do we get better results with a different threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 26556\n",
    "threshold = 1000\n",
    "\n",
    "# TODO fill in code here to generate our top 5 predictions having a minimum number of ratings. Assign\n",
    "# a dataframe with these movies to reccs.\n",
    "reccs = []\n",
    "#q4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId_orig</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18811</th>\n",
       "      <td>18811</td>\n",
       "      <td>The Cabin in the Woods</td>\n",
       "      <td>Comedy|Horror|Sci-Fi|Thriller</td>\n",
       "      <td>93840</td>\n",
       "      <td>Cabin in the Woods, The (2012)</td>\n",
       "      <td>2012</td>\n",
       "      <td>1757</td>\n",
       "      <td>3.677778</td>\n",
       "      <td>5.557921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>1233</td>\n",
       "      <td>Evil Dead II (Dead by Dawn)</td>\n",
       "      <td>Action|Comedy|Fantasy|Horror</td>\n",
       "      <td>1261</td>\n",
       "      <td>Evil Dead II (Dead by Dawn) (1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>7788</td>\n",
       "      <td>3.772697</td>\n",
       "      <td>5.304120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>2614</td>\n",
       "      <td>South Park: Bigger, Longer and Uncut</td>\n",
       "      <td>Animation|Comedy|Musical</td>\n",
       "      <td>2700</td>\n",
       "      <td>South Park: Bigger, Longer and Uncut (1999)</td>\n",
       "      <td>1999</td>\n",
       "      <td>17371</td>\n",
       "      <td>3.626352</td>\n",
       "      <td>5.202606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>1189</td>\n",
       "      <td>Army of Darkness</td>\n",
       "      <td>Action|Adventure|Comedy|Fantasy|Horror</td>\n",
       "      <td>1215</td>\n",
       "      <td>Army of Darkness (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>12469</td>\n",
       "      <td>3.723848</td>\n",
       "      <td>5.187201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>1213</td>\n",
       "      <td>Dead Alive (Braindead)</td>\n",
       "      <td>Comedy|Fantasy|Horror</td>\n",
       "      <td>1241</td>\n",
       "      <td>Dead Alive (Braindead) (1992)</td>\n",
       "      <td>1992</td>\n",
       "      <td>2576</td>\n",
       "      <td>3.722017</td>\n",
       "      <td>5.079439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                 title  \\\n",
       "18811    18811                The Cabin in the Woods   \n",
       "1233      1233           Evil Dead II (Dead by Dawn)   \n",
       "2614      2614  South Park: Bigger, Longer and Uncut   \n",
       "1189      1189                      Army of Darkness   \n",
       "1213      1213                Dead Alive (Braindead)   \n",
       "\n",
       "                                       genres  movieId_orig  \\\n",
       "18811           Comedy|Horror|Sci-Fi|Thriller         93840   \n",
       "1233             Action|Comedy|Fantasy|Horror          1261   \n",
       "2614                 Animation|Comedy|Musical          2700   \n",
       "1189   Action|Adventure|Comedy|Fantasy|Horror          1215   \n",
       "1213                    Comedy|Fantasy|Horror          1241   \n",
       "\n",
       "                                               key  year  n_ratings  \\\n",
       "18811               Cabin in the Woods, The (2012)  2012       1757   \n",
       "1233            Evil Dead II (Dead by Dawn) (1987)  1987       7788   \n",
       "2614   South Park: Bigger, Longer and Uncut (1999)  1999      17371   \n",
       "1189                       Army of Darkness (1993)  1993      12469   \n",
       "1213                 Dead Alive (Braindead) (1992)  1992       2576   \n",
       "\n",
       "       mean_rating  predicted_rating  \n",
       "18811     3.677778          5.557921  \n",
       "1233      3.772697          5.304120  \n",
       "2614      3.626352          5.202606  \n",
       "1189      3.723848          5.187201  \n",
       "1213      3.722017          5.079439  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4.solution()\n",
    "reccs = movies_df[movies_df.n_ratings >= threshold]\\\n",
    "    .sort_values(by='predicted_rating', ascending=False).head(5)\n",
    "reccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Fixing our obscure recommendation problem (regularization)\n",
    "\n",
    "The code below is identical to the code used to create the model we've been using in this exercise, except we've added L2 regularization to our embeddings (by specifying a value for the keyword argument `embeddings_regularizer` when creating our Embedding layers).\n",
    "\n",
    "> **TODO: Aside here giving an introduction to regularization via weight penalty. Intuitive interpretation (imposing a prior), and mechanics of how it works (adding a term to the loss calculated as blah).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embedding_size = user_embedding_size = 8\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "l2_model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this model for a decent number of iterations takes around 15 minutes, so to save some time, I have an already trained model you can load from disk by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "l2_model = keras.models.load_model('movie_svd_model_8_r12n.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TODO: Note on the fact that this does indeed end up improving validation MAE. And maybe note effect on overfitting? Show plot of train and val loss, with and w/o r12n)**\n",
    "\n",
    "Try using the code you wrote in part 1 to generate recommendations using this model. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call function defined in part 1 using l2_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think this model's predicted scores will look like for the 'obscure' movies that our earlier model highly recommended? Run the cell below to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId_orig</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>l2_predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21770</th>\n",
       "      <td>21770</td>\n",
       "      <td>McKenna Shoots for the Stars</td>\n",
       "      <td>Children|Drama</td>\n",
       "      <td>105563</td>\n",
       "      <td>McKenna Shoots for the Stars (2012)</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>4.250</td>\n",
       "      <td>8.314218</td>\n",
       "      <td>3.516182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25793</th>\n",
       "      <td>25793</td>\n",
       "      <td>Babette Goes to War</td>\n",
       "      <td>Comedy|War</td>\n",
       "      <td>126126</td>\n",
       "      <td>Babette Goes to War (1959)</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>7.968132</td>\n",
       "      <td>3.527207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25794</th>\n",
       "      <td>25794</td>\n",
       "      <td>Belle comme la femme d'un autre</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>126128</td>\n",
       "      <td>Belle comme la femme d'un autre (2014)</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.963298</td>\n",
       "      <td>3.523645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26329</th>\n",
       "      <td>26329</td>\n",
       "      <td>Sense &amp; Sensibility</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>129032</td>\n",
       "      <td>Sense &amp; Sensibility (2008)</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>4.125</td>\n",
       "      <td>7.767604</td>\n",
       "      <td>3.521172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25823</th>\n",
       "      <td>25823</td>\n",
       "      <td>The Sex and Violence Family Hour</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>126186</td>\n",
       "      <td>The Sex and Violence Family Hour (1983)</td>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>7.720160</td>\n",
       "      <td>3.517339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                             title              genres  \\\n",
       "21770    21770      McKenna Shoots for the Stars      Children|Drama   \n",
       "25793    25793               Babette Goes to War          Comedy|War   \n",
       "25794    25794   Belle comme la femme d'un autre              Comedy   \n",
       "26329    26329               Sense & Sensibility       Drama|Romance   \n",
       "25823    25823  The Sex and Violence Family Hour  (no genres listed)   \n",
       "\n",
       "       movieId_orig                                      key  year  n_ratings  \\\n",
       "21770        105563      McKenna Shoots for the Stars (2012)  2012          2   \n",
       "25793        126126               Babette Goes to War (1959)  1959          1   \n",
       "25794        126128   Belle comme la femme d'un autre (2014)  2014          1   \n",
       "26329        129032               Sense & Sensibility (2008)  2008          4   \n",
       "25823        126186  The Sex and Violence Family Hour (1983)  1983          1   \n",
       "\n",
       "       mean_rating  predicted_rating  l2_predicted_rating  \n",
       "21770        4.250          8.314218             3.516182  \n",
       "25793        1.500          7.968132             3.527207  \n",
       "25794        1.000          7.963298             3.523645  \n",
       "26329        4.125          7.767604             3.521172  \n",
       "25823        1.500          7.720160             3.517339  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = 26556\n",
    "reccs = movies_df.sort_values(by='predicted_rating', ascending=False).head(n)\n",
    "obscure_mids = reccs.index\n",
    "preds = l2_model.predict([\n",
    "    np.repeat(uid, len(obscure_mids)),\n",
    "    obscure_mids,\n",
    "])\n",
    "recc_df = movies_df.loc[obscure_mids].copy()\n",
    "recc_df['l2_predicted_rating'] = preds + offset\n",
    "recc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`</exercise>`\n",
    "\n",
    "# Scratch space below - please ignore\n",
    "\n",
    "```\n",
    "TODO\n",
    "- (maybe) look at dist. of weights of r12n model vs. prev model\n",
    "- (maybe) load another pretrained model with even stronger r12n. Compare reccs. What's the behaviour in the limit as we increase r12n strength?\n",
    "- Look at reccs for a few other users with fairly clear, distinctive tastes. e.g...\n",
    "    112287 (American Beauty, The Notebook, Mean Girls, The Devil Wears Prada)\n",
    "    69106 (Terminator 2, Toy Story, WALL-E, Days of Thunder, Star Wars, The Matrix)\n",
    "    83421 (The Godfather, The Shawshank Redemption, Casino, Casablanca)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 500\n",
    "movies_df[movies_df.n_ratings > thresh]\\\n",
    "    .sort_values(by='predicted_rating', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, = model.get_layer('movie_embedding').get_weights()\n",
    "\n",
    "w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, = model.get_layer('user_embedding').get_weights()\n",
    "\n",
    "w[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, = model.get_layer('movie_embedding').get_weights()\n",
    "wu, = model.get_layer('user_embedding').get_weights()\n",
    "\n",
    "print(\n",
    "    np.linalg.norm(wm[0]),\n",
    "    np.linalg.norm(wm[1]),\n",
    "    np.linalg.norm(wm[2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.linalg.norm(wm, axis=1)\n",
    "ns = pd.Series(norms)\n",
    "\n",
    "\n",
    "unorms = np.linalg.norm(wu, axis=1)\n",
    "nus = pd.Series(unorms)\n",
    "display(\n",
    "    \"Dist of movie norms:\",\n",
    "    ns.describe(),\n",
    "    \"Dist of user norms:\",\n",
    "    nus.describe(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "wm, = model.get_layer('movie_embedding').get_weights()\n",
    "wu, = model.get_layer('user_embedding').get_weights()\n",
    "\n",
    "quantiles = [.1, .25, .4, .5, .6, .75, .9]\n",
    "\n",
    "display(\n",
    "    \"Movie embedding weights:\",\n",
    "    pd.Series(wm.flatten()).describe(quantiles),\n",
    "    \"User embedding weights:\",\n",
    "    pd.Series(wu.flatten()).describe(quantiles),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "wm, = model.get_layer('movie_embedding').get_weights()\n",
    "wu, = model.get_layer('user_embedding').get_weights()\n",
    "bm, = model.get_layer('movie_bias').get_weights()\n",
    "bu, = model.get_layer('user_bias').get_weights()\n",
    "\n",
    "quantiles = [.1, .25, .4, .5, .6, .75, .9]\n",
    "\n",
    "display(\n",
    "    pd.Series(wm.flatten()).describe(quantiles),\n",
    "    pd.Series(wu.flatten()).describe(quantiles),\n",
    "    pd.Series(bm.flatten()).describe(quantiles),\n",
    "    pd.Series(bu.flatten()).describe(quantiles),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uggggh. Remember to do this before any training experiments.\n",
    "df = df.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: New experiment - dropout?\n",
    "movie_embedding_size = user_embedding_size = 32\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "dropout = .2\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "user_embedded = keras.layers.Dropout(dropout)(user_embedded)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "movie_embedded = keras.layers.Dropout(dropout)(movie_embedded)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")\n",
    "model.compile(\n",
    "    tf.train.AdamOptimizer(0.001),\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "\n",
    "tf.set_random_seed(1); np.random.seed(1); random.seed(1)\n",
    "history = model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=15,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('movie_svd_model_32_dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embedding_size = user_embedding_size = 32\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "#movie_r12n = user_r12n = None # zzz\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "biases = 0\n",
    "if biases:\n",
    "    bias_r12n = None\n",
    "    bias_r12n = keras.regularizers.l1_l2(l1=1e-4, l2=1e-7) # XXX 1e-6 -> 1e-4\n",
    "    bias_init = 'zeros'\n",
    "    movie_b = keras.layers.Embedding(df.movieId.max()+1, 1, \n",
    "                                             name='movie_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(movie_id_input)\n",
    "    movie_b = keras.layers.Flatten()(movie_b)\n",
    "    #out = keras.layers.Add()([movie_b, out])\n",
    "\n",
    "    user_b = keras.layers.Embedding(df.userId.max()+1, 1, \n",
    "                                             name='user_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(user_id_input)\n",
    "    user_b = keras.layers.Flatten()(user_b)\n",
    "    out = keras.layers.Add()([user_b, movie_b, out])\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")\n",
    "model.compile(\n",
    "    tf.train.AdamOptimizer(0.001), # XXX: Try lower?\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "#model.summary()\n",
    "\n",
    "tf.set_random_seed(1); np.random.seed(1); random.seed(1)\n",
    "history = model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embedding_size = user_embedding_size = 32\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "#movie_r12n = user_r12n = None # zzz\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "biases = 0\n",
    "if biases:\n",
    "    bias_r12n = None\n",
    "    bias_r12n = keras.regularizers.l1_l2(l1=1e-4, l2=1e-7) # XXX 1e-6 -> 1e-4\n",
    "    bias_init = 'zeros'\n",
    "    movie_b = keras.layers.Embedding(df.movieId.max()+1, 1, \n",
    "                                             name='movie_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(movie_id_input)\n",
    "    movie_b = keras.layers.Flatten()(movie_b)\n",
    "    #out = keras.layers.Add()([movie_b, out])\n",
    "\n",
    "    user_b = keras.layers.Embedding(df.userId.max()+1, 1, \n",
    "                                             name='user_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(user_id_input)\n",
    "    user_b = keras.layers.Flatten()(user_b)\n",
    "    out = keras.layers.Add()([user_b, movie_b, out])\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")\n",
    "model.compile(\n",
    "    tf.train.AdamOptimizer(0.001), # XXX: Try lower?\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "#model.summary()\n",
    "\n",
    "tf.set_random_seed(1); np.random.seed(1); random.seed(1)\n",
    "history = model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('movie_svd_model_8_r12n.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=8,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, this is excellent. Biases seem shockingly low. \n",
    "# I wonder if accuracy is much affected by just taking them away?\n",
    "# XXX: lower lr experiment\n",
    "movie_embedding_size = user_embedding_size = 16 # XXX: Tested with 8 (and worked well there). idk if \n",
    "# r12n might need to go up when increasing the number of parameters like this?\n",
    "\n",
    "# Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "#movie_r12n = user_r12n = None # zzz\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "biases = 1\n",
    "if biases:\n",
    "    bias_r12n = None\n",
    "    bias_r12n = keras.regularizers.l1_l2(l1=1e-4, l2=1e-7) # XXX 1e-6 -> 1e-4\n",
    "    bias_init = 'zeros'\n",
    "    movie_b = keras.layers.Embedding(df.movieId.max()+1, 1, \n",
    "                                             name='movie_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(movie_id_input)\n",
    "    movie_b = keras.layers.Flatten()(movie_b)\n",
    "    #out = keras.layers.Add()([movie_b, out])\n",
    "\n",
    "    user_b = keras.layers.Embedding(df.userId.max()+1, 1, \n",
    "                                             name='user_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(user_id_input)\n",
    "    user_b = keras.layers.Flatten()(user_b)\n",
    "    out = keras.layers.Add()([user_b, movie_b, out])\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")\n",
    "model.compile(\n",
    "    tf.train.AdamOptimizer(0.001), # XXX: Try lower?\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "#model.summary()\n",
    "\n",
    "tf.set_random_seed(1); np.random.seed(1); random.seed(1)\n",
    "history = model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=60,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('movie_svd_model_16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(preds.flatten()).describe([.05, .1, .25, .5, .75, .9, .95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These reccos suck. OTOH, this is a great motivator/lead-in to r12n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch space / brainstorm\n",
    "\n",
    "Idea: focus on r12n? (In the same way that I was thinking of having ex 1 be walking through adding biases step by step.)\n",
    "\n",
    "Are there other datasets I could have them do factorization on? (Could then be fun to use those learned embeddings for next two exercises)\n",
    "\n",
    "- million song dataset https://www.kaggle.com/c/msdchallenge\n",
    "- goodreads https://www.kaggle.com/zygmunt/goodbooks-10k/home <--- this one looks promising\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "This technique makes it easier to generate recommendations for a particular user. Let's try it. (I guess this is a point where having some understanding of the matrix factorization aspect would be useful.)\n",
    "\n",
    "To make recommendations for user u...\n",
    "- could individually calculate predicted scores for every movie in the dataset, but that'd be pretty tedious.\n",
    "- multiply user vector by weight matrix to get a column vector with predicted scores per movie. Sort.\n",
    "\n",
    "## convergence properties (thought experiment)\n",
    "\n",
    "Compare the loss over time of some DNN models like the ones we trained yesterday vs. some factorization models. Do you notice a difference? Can you think of why this would be?\n",
    "\n",
    "## factorization vs. dnn (thought experiment)\n",
    "\n",
    "We seem to be getting better results with our factorization model. But can you think of situations where you would want to use the dnn model instead?\n",
    "\n",
    "## r12n\n",
    "\n",
    "Look at train vs. val loss for different embedding sizes. How could we prevent overfitting while keeping a larger embedding size? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
