{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (Matrix Factorization)\n",
    "\n",
    "In this lesson, we'll reuse the model we trained in [the tutorial](#$TUTORIAL_URL(2)$). To get started, run the setup cell below to import the libraries we'll be using, load our data into Dataframes, and load a serialized version of the model we trained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "\n",
    "input_dir = '../input/movielens_preprocessed'\n",
    "df = pd.read_csv(os.path.join(input_dir, 'rating.csv'), usecols=['userId', 'movieId', 'rating', 'y'])\n",
    "#movies_df = pd.read_csv(os.path.join(input_dir, 'movie.csv'), usecols=['movieId', 'title', 'year']).set_index('movieId', drop=False)\n",
    "movies = movies_df = pd.read_csv(os.path.join(input_dir, 'movie.csv'), index_col=0)\n",
    "\n",
    "# TODO: suppress warning\n",
    "model = keras.models.load_model('factorization_model.h5')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generating Recommendations\n",
    "\n",
    "At the end of [the first lesson where we built an embedding model](#$TUTORIAL_URL(1)$), I showed how we could use our model to predict the ratings a particular user would give to some set of movies.\n",
    "\n",
    "For reference, here's a (slightly modified) copy of that code where we calculated predicted ratings for 5 specific movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>366</td>\n",
       "      <td>Naked Gun 33 1/3: The Final Insult</td>\n",
       "      <td>3.761640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>3775</td>\n",
       "      <td>The Naked Gun: From the Files of Police Squad!</td>\n",
       "      <td>4.945276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>3776</td>\n",
       "      <td>The Naked Gun 2 1/2: The Smell of Fear</td>\n",
       "      <td>4.457918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>5347</td>\n",
       "      <td>Lilo &amp; Stitch</td>\n",
       "      <td>3.753898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10138</th>\n",
       "      <td>10138</td>\n",
       "      <td>The Sisterhood of the Traveling Pants</td>\n",
       "      <td>1.969995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                           title  \\\n",
       "366        366              Naked Gun 33 1/3: The Final Insult   \n",
       "3775      3775  The Naked Gun: From the Files of Police Squad!   \n",
       "3776      3776          The Naked Gun 2 1/2: The Smell of Fear   \n",
       "5347      5347                                   Lilo & Stitch   \n",
       "10138    10138           The Sisterhood of the Traveling Pants   \n",
       "\n",
       "       predicted_rating  \n",
       "366            3.761640  \n",
       "3775           4.945276  \n",
       "3776           4.457918  \n",
       "5347           3.753898  \n",
       "10138          1.969995  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = 26556\n",
    "candidate_movies = movies[\n",
    "    movies.title.str.contains('Naked Gun')\n",
    "    | (movies.title == 'The Sisterhood of the Traveling Pants')\n",
    "    | (movies.title == 'Lilo & Stitch')\n",
    "].copy()\n",
    "\n",
    "preds = model.predict([\n",
    "    [uid] * len(candidate_movies), # User ids \n",
    "    candidate_movies.index, # Movie ids\n",
    "])\n",
    "# Because our model was trained on a 'centered' version of rating (subtracting the mean, so that\n",
    "# the target variable had mean 0), to get the predicted star rating on the original scale, we need\n",
    "# to add the mean back in.\n",
    "row0 = df.iloc[0]\n",
    "offset = row0.rating - row0.y\n",
    "candidate_movies['predicted_rating'] = preds + offset\n",
    "candidate_movies.head()[ ['movieId', 'title', 'predicted_rating'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we're interested in the somewhat more open-ended problem of **generating recommendations**. i.e. given some user ID and some number `k`, we need to generate a list of `k` movies we think the user will enjoy.\n",
    "\n",
    "The most straightforward way to do this would be to calculate the predicted rating this user would assign for *every movie in the dataset*, then take the movies with the `k` highest predictions.\n",
    "\n",
    "In the code cell below, write code to create a variable `reccs` containing the 5 movies with the highest predicted rating for the user with userId 26556. `reccs` should be a DataFrame with a `movieId` column (it can also have any other additional columns you'd like).\n",
    "\n",
    "**TODO: Maybe have them fill in the body of a function for generating recommendations instead? That way, it would be easy for them to reuse it later on to get reccs for other models that we load (in part 5). Or try it on other users. fn would take model, k, and uid as inputs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(model, user_id, n=5):\n",
    "    \"\"\"Return a DataFrame with the n most highly recommended movies for the user with the\n",
    "    given id. (Where most highly recommended means having the highest predicted ratings \n",
    "    according to the given model).\n",
    "    \"\"\"\n",
    "    # 1. Create a list/array containing all movie ids (from the movies dataframe)\n",
    "    # 2. Call model.predict() on a list/array with repeated copies of uid, and the sequence you created in step 1\n",
    "    # 3. Return the movieIds associated with the 5 highest values returned in step 2. The easiest thing may be to\n",
    "    #    add a 'predicted_rating' column to the movies dataframe (or a copy of it), then sort on that column.\n",
    "    pass\n",
    "\n",
    "#part1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21770</th>\n",
       "      <td>21770</td>\n",
       "      <td>McKenna Shoots for the Stars</td>\n",
       "      <td>Children|Drama</td>\n",
       "      <td>McKenna Shoots for the Stars (2012)</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>4.250</td>\n",
       "      <td>8.314224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25793</th>\n",
       "      <td>25793</td>\n",
       "      <td>Babette Goes to War</td>\n",
       "      <td>Comedy|War</td>\n",
       "      <td>Babette Goes to War (1959)</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>7.968139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25794</th>\n",
       "      <td>25794</td>\n",
       "      <td>Belle comme la femme d'un autre</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Belle comme la femme d'un autre (2014)</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.963304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26329</th>\n",
       "      <td>26329</td>\n",
       "      <td>Sense &amp; Sensibility</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>Sense &amp; Sensibility (2008)</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>4.125</td>\n",
       "      <td>7.767611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25823</th>\n",
       "      <td>25823</td>\n",
       "      <td>The Sex and Violence Family Hour</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>The Sex and Violence Family Hour (1983)</td>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>7.720166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                             title              genres  \\\n",
       "21770    21770      McKenna Shoots for the Stars      Children|Drama   \n",
       "25793    25793               Babette Goes to War          Comedy|War   \n",
       "25794    25794   Belle comme la femme d'un autre              Comedy   \n",
       "26329    26329               Sense & Sensibility       Drama|Romance   \n",
       "25823    25823  The Sex and Violence Family Hour  (no genres listed)   \n",
       "\n",
       "                                           key  year  n_ratings  mean_rating  \\\n",
       "21770      McKenna Shoots for the Stars (2012)  2012          2        4.250   \n",
       "25793               Babette Goes to War (1959)  1959          1        1.500   \n",
       "25794   Belle comme la femme d'un autre (2014)  2014          1        1.000   \n",
       "26329               Sense & Sensibility (2008)  2008          4        4.125   \n",
       "25823  The Sex and Violence Family Hour (1983)  1983          1        1.500   \n",
       "\n",
       "       predicted_rating  \n",
       "21770          8.314224  \n",
       "25793          7.968139  \n",
       "25794          7.963304  \n",
       "26329          7.767611  \n",
       "25823          7.720166  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1.solution()\n",
    "def recommend(model, user_id, n=5):\n",
    "    \"\"\"Return a DataFrame with the n most highly recommended movies for the user with the\n",
    "    given id. (Where most highly recommended means having the highest predicted ratings \n",
    "    according to the given model).\n",
    "    \"\"\"\n",
    "    all_movie_ids = df.movieId.unique()\n",
    "    preds = model.predict([\n",
    "        np.repeat(uid, len(all_movie_ids)),\n",
    "        all_movie_ids,\n",
    "    ])\n",
    "    # Add back the offset calculated earlier, to 'uncenter' the ratings, and get back to a [0.5, 5] scale.\n",
    "    movies_df.loc[all_movie_ids, 'predicted_rating'] = preds + offset\n",
    "    reccs = movies_df.sort_values(by='predicted_rating', ascending=False).head(n)\n",
    "    return reccs\n",
    "\n",
    "uid = 26556\n",
    "recommend(model, uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sanity check\n",
    "\n",
    "Do these recommendations seem sensible? If you'd like a reminder of user 26556's tastes, run the cell below to see all their ratings (in descending order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>y</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26556</td>\n",
       "      <td>2706</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.474498</td>\n",
       "      <td>Airplane II: The Sequel</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1982</td>\n",
       "      <td>4284</td>\n",
       "      <td>3.046287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26556</td>\n",
       "      <td>2705</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.474498</td>\n",
       "      <td>Airplane!</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1980</td>\n",
       "      <td>18866</td>\n",
       "      <td>3.795963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26556</td>\n",
       "      <td>2863</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974498</td>\n",
       "      <td>Dr. No</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>1962</td>\n",
       "      <td>7183</td>\n",
       "      <td>3.687600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26556</td>\n",
       "      <td>2102</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974498</td>\n",
       "      <td>Strangers on a Train</td>\n",
       "      <td>Crime|Drama|Film-Noir|Thriller</td>\n",
       "      <td>1951</td>\n",
       "      <td>5154</td>\n",
       "      <td>4.160627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26556</td>\n",
       "      <td>2216</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974498</td>\n",
       "      <td>History of the World: Part I</td>\n",
       "      <td>Comedy|Musical</td>\n",
       "      <td>1981</td>\n",
       "      <td>4313</td>\n",
       "      <td>3.595760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26556</td>\n",
       "      <td>534</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974498</td>\n",
       "      <td>Six Degrees of Separation</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1993</td>\n",
       "      <td>5101</td>\n",
       "      <td>3.707337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26556</td>\n",
       "      <td>937</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974498</td>\n",
       "      <td>Mr. Smith Goes to Washington</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1939</td>\n",
       "      <td>5712</td>\n",
       "      <td>4.037443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26556</td>\n",
       "      <td>2286</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.974498</td>\n",
       "      <td>Fletch</td>\n",
       "      <td>Comedy|Crime|Mystery</td>\n",
       "      <td>1985</td>\n",
       "      <td>6298</td>\n",
       "      <td>3.453211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26556</td>\n",
       "      <td>913</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>Notorious</td>\n",
       "      <td>Film-Noir|Romance|Thriller</td>\n",
       "      <td>1946</td>\n",
       "      <td>4932</td>\n",
       "      <td>4.196818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26556</td>\n",
       "      <td>730</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>Spy Hard</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1996</td>\n",
       "      <td>6112</td>\n",
       "      <td>2.735314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26556</td>\n",
       "      <td>3890</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>Diamonds Are Forever</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>1971</td>\n",
       "      <td>4357</td>\n",
       "      <td>3.513199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26556</td>\n",
       "      <td>916</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>To Catch a Thief</td>\n",
       "      <td>Crime|Mystery|Romance|Thriller</td>\n",
       "      <td>1955</td>\n",
       "      <td>4699</td>\n",
       "      <td>4.028382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26556</td>\n",
       "      <td>3414</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.025502</td>\n",
       "      <td>Network</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>1976</td>\n",
       "      <td>5206</td>\n",
       "      <td>4.023397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26556</td>\n",
       "      <td>4917</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.025502</td>\n",
       "      <td>Gosford Park</td>\n",
       "      <td>Comedy|Drama|Mystery</td>\n",
       "      <td>2001</td>\n",
       "      <td>6182</td>\n",
       "      <td>3.627007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26556</td>\n",
       "      <td>1414</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.025502</td>\n",
       "      <td>Waiting for Guffman</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1996</td>\n",
       "      <td>5957</td>\n",
       "      <td>3.944287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26556</td>\n",
       "      <td>2907</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.025502</td>\n",
       "      <td>Thunderball</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>1965</td>\n",
       "      <td>4210</td>\n",
       "      <td>3.621468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26556</td>\n",
       "      <td>1861</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.525502</td>\n",
       "      <td>On the Waterfront</td>\n",
       "      <td>Crime|Drama</td>\n",
       "      <td>1954</td>\n",
       "      <td>5644</td>\n",
       "      <td>4.163927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26556</td>\n",
       "      <td>1082</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-1.025502</td>\n",
       "      <td>A Streetcar Named Desire</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1951</td>\n",
       "      <td>6372</td>\n",
       "      <td>4.010934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26556</td>\n",
       "      <td>3445</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-1.025502</td>\n",
       "      <td>Keeping the Faith</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>2000</td>\n",
       "      <td>4033</td>\n",
       "      <td>3.461468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26556</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.525502</td>\n",
       "      <td>The Day the Earth Stood Still</td>\n",
       "      <td>Drama|Sci-Fi|Thriller</td>\n",
       "      <td>1951</td>\n",
       "      <td>6259</td>\n",
       "      <td>3.932131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>26556</td>\n",
       "      <td>2348</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-3.025502</td>\n",
       "      <td>A Civil Action</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1998</td>\n",
       "      <td>3965</td>\n",
       "      <td>3.335064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating         y                          title  \\\n",
       "0    26556     2706     5.0  1.474498        Airplane II: The Sequel   \n",
       "1    26556     2705     5.0  1.474498                      Airplane!   \n",
       "2    26556     2863     4.5  0.974498                         Dr. No   \n",
       "3    26556     2102     4.5  0.974498           Strangers on a Train   \n",
       "4    26556     2216     4.5  0.974498   History of the World: Part I   \n",
       "5    26556      534     4.5  0.974498      Six Degrees of Separation   \n",
       "6    26556      937     4.5  0.974498   Mr. Smith Goes to Washington   \n",
       "7    26556     2286     4.5  0.974498                         Fletch   \n",
       "8    26556      913     4.0  0.474498                      Notorious   \n",
       "9    26556      730     4.0  0.474498                       Spy Hard   \n",
       "10   26556     3890     4.0  0.474498           Diamonds Are Forever   \n",
       "11   26556      916     4.0  0.474498               To Catch a Thief   \n",
       "12   26556     3414     3.5 -0.025502                        Network   \n",
       "13   26556     4917     3.5 -0.025502                   Gosford Park   \n",
       "14   26556     1414     3.5 -0.025502            Waiting for Guffman   \n",
       "15   26556     2907     3.5 -0.025502                    Thunderball   \n",
       "16   26556     1861     3.0 -0.525502              On the Waterfront   \n",
       "17   26556     1082     2.5 -1.025502       A Streetcar Named Desire   \n",
       "18   26556     3445     2.5 -1.025502              Keeping the Faith   \n",
       "19   26556     1225     2.0 -1.525502  The Day the Earth Stood Still   \n",
       "20   26556     2348     0.5 -3.025502                 A Civil Action   \n",
       "\n",
       "                            genres  year  n_ratings  mean_rating  \n",
       "0                           Comedy  1982       4284     3.046287  \n",
       "1                           Comedy  1980      18866     3.795963  \n",
       "2        Action|Adventure|Thriller  1962       7183     3.687600  \n",
       "3   Crime|Drama|Film-Noir|Thriller  1951       5154     4.160627  \n",
       "4                   Comedy|Musical  1981       4313     3.595760  \n",
       "5                            Drama  1993       5101     3.707337  \n",
       "6                            Drama  1939       5712     4.037443  \n",
       "7             Comedy|Crime|Mystery  1985       6298     3.453211  \n",
       "8       Film-Noir|Romance|Thriller  1946       4932     4.196818  \n",
       "9                           Comedy  1996       6112     2.735314  \n",
       "10       Action|Adventure|Thriller  1971       4357     3.513199  \n",
       "11  Crime|Mystery|Romance|Thriller  1955       4699     4.028382  \n",
       "12                    Comedy|Drama  1976       5206     4.023397  \n",
       "13            Comedy|Drama|Mystery  2001       6182     3.627007  \n",
       "14                          Comedy  1996       5957     3.944287  \n",
       "15       Action|Adventure|Thriller  1965       4210     3.621468  \n",
       "16                     Crime|Drama  1954       5644     4.163927  \n",
       "17                           Drama  1951       6372     4.010934  \n",
       "18            Comedy|Drama|Romance  2000       4033     3.461468  \n",
       "19           Drama|Sci-Fi|Thriller  1951       6259     3.932131  \n",
       "20                           Drama  1998       3965     3.335064  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings = df[df.userId==uid]\n",
    "movie_cols = ['movieId', 'title', 'genres', 'year', 'n_ratings', 'mean_rating']\n",
    "user_ratings.sort_values(by='rating', ascending=False).merge(movies[movie_cols], on='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review our top-recommended movies. Are they good or bad? If they're bad, in what way are they bad? You may also find it interesting to look at:\n",
    "- The metadata associated with the top-recommended movies\n",
    "- The 'least-recommended' movies (the ones with the lowest predicted scores)\n",
    "- The actual predicted rating values.\n",
    "\n",
    "Once you have an opinion, uncomment the cell below to see if we're in agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#q2.solution()`\n",
    "\n",
    "I'm going to claim that these recommended movies are **bad**. In terms of genre and themes, our top picks seem like poor fits. User 26556 has pretty mature tastes - they like Hitchcock, classic James Bond, and Leslie Nielsen comedies. But our top pick for them, *McKenna Shoots for the Stars*, seems squarely aimed at pre-teen girls.\n",
    "\n",
    "Though I had to google the title to discover that fact. In fact, I didn't recognize any of the films in our top-5 recommendations. And that speaks to the biggest problem with our recommendations: they're **super obscure**. Our top 5 recommendations only have a total of 9 reviews between them in the whole dataset. We barely know anything about these movies - how can we be so confident that user 26556 is going to love them?\n",
    "\n",
    "This is similar to the problem we encountered in the previous exercise, where our model confidently assigned extreme bias values to movies with only a tiny number of reviews.\n",
    "\n",
    "> **Aside:** You may have noticed another problem, which becomes very obvious when we look at the movies with \n",
    "the highest (or lowest) predicted scores: sometimes our model predicts values outside the allowable\n",
    "range of 0.5-5 stars. For the purposes of recommendation, this is actually no problem: we only care about ranking\n",
    "movies, not about the absolute values of their predicted scores. But this is still an interesting problem\n",
    "to consider. How could we prevent our model from incurring needless errors by making predictions outside\n",
    "the allowable range? Should we? If you have ideas, head over to [this forum thread](TODO) to discuss.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: How are we going to fix this mess?\n",
    "\n",
    "How can we improve the problem with our recommendations that we identified in Part 2? This could involve changing our model's structure, our training procedure, or our procedure for generating recommendations given a model.\n",
    "\n",
    "Give it some thought, then uncomment the cell below to compare notes with me. (If you have no idea, that's totally fine!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`q3.solution()`\n",
    "\n",
    "One simple solution would be limiting our recommendations to movies with at least `n` ratings. This feels inelegant, in that we have to choose some arbitrary cut-off, and any reasonable choice will probably exclude some good recommendations. It would be nice if we could take into account popularity in a 'smoother' way. On the other hand, this is very simple to implement, and we don't even need to re-train our model, so it's worth a shot.\n",
    "\n",
    "If we're willing to train a new model, there's another less hacky approach we can take which might fix our obscure recommendation problem *and* improve our overall accuracy at the same time: regularization. Specifically, putting an L2 weight penalty on our embeddings. I'll talk more about this in part 5 (and show how we would implement it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Fixing our obscure recommendation problem (thresholding)\n",
    "\n",
    "Fill in the code cell below to implement the `recommend_nonobscure` function, which will recommend the best movies which have at least some minimum number of ratings. (You may wish to modify the code you wrote in `recommend`, or even call `recommend` as a subroutine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_nonobscure(model, user_id, n=5, min_ratings=1000):\n",
    "    \"\"\"Return a DataFrame with the n movies which the given model assigns the highest \n",
    "    predicted ratings for the given user, *limited to movies with at least the given\n",
    "    threshold of ratings*.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "#q4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q4.solution()\n",
    "def recommend_nonobscure(model, user_id, n=5, min_ratings=1000):\n",
    "    \"\"\"Return a DataFrame with the n movies which the given model assigns the highest \n",
    "    predicted ratings for the given user, *limited to movies with at least the given\n",
    "    threshold of ratings*.\n",
    "    \"\"\"\n",
    "    # Add predicted_rating column if we haven't already done so.\n",
    "    if 'predicted_rating' not in movies.columns:\n",
    "        all_movie_ids = df.movieId.unique()\n",
    "        preds = model.predict([\n",
    "            np.repeat(uid, len(all_movie_ids)),\n",
    "            all_movie_ids,\n",
    "        ])\n",
    "        # Add back the offset calculated earlier, to 'uncenter' the ratings, and get back to a [0.5, 5] scale.\n",
    "        movies_df.loc[all_movie_ids, 'predicted_rating'] = preds + offset\n",
    "    \n",
    "    nonobscure_movie_ids = movies.index[movies.n_ratings >= min_ratings]\n",
    "    return movies.loc[nonobscure_movie_ids].sort_values(by='predicted_rating', ascending=False).head(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to take a look at our new recommended movies. Did this fix our problem? Do we get better results with a different threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18811</th>\n",
       "      <td>18811</td>\n",
       "      <td>The Cabin in the Woods</td>\n",
       "      <td>Comedy|Horror|Sci-Fi|Thriller</td>\n",
       "      <td>Cabin in the Woods, The (2012)</td>\n",
       "      <td>2012</td>\n",
       "      <td>1757</td>\n",
       "      <td>3.677391</td>\n",
       "      <td>5.557927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>1233</td>\n",
       "      <td>Evil Dead II (Dead by Dawn)</td>\n",
       "      <td>Action|Comedy|Fantasy|Horror</td>\n",
       "      <td>Evil Dead II (Dead by Dawn) (1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>7788</td>\n",
       "      <td>3.772888</td>\n",
       "      <td>5.304126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>2614</td>\n",
       "      <td>South Park: Bigger, Longer and Uncut</td>\n",
       "      <td>Animation|Comedy|Musical</td>\n",
       "      <td>South Park: Bigger, Longer and Uncut (1999)</td>\n",
       "      <td>1999</td>\n",
       "      <td>17371</td>\n",
       "      <td>3.626832</td>\n",
       "      <td>5.202612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>1189</td>\n",
       "      <td>Army of Darkness</td>\n",
       "      <td>Action|Adventure|Comedy|Fantasy|Horror</td>\n",
       "      <td>Army of Darkness (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>12469</td>\n",
       "      <td>3.723536</td>\n",
       "      <td>5.187207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>1213</td>\n",
       "      <td>Dead Alive (Braindead)</td>\n",
       "      <td>Comedy|Fantasy|Horror</td>\n",
       "      <td>Dead Alive (Braindead) (1992)</td>\n",
       "      <td>1992</td>\n",
       "      <td>2576</td>\n",
       "      <td>3.727050</td>\n",
       "      <td>5.079445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                 title  \\\n",
       "18811    18811                The Cabin in the Woods   \n",
       "1233      1233           Evil Dead II (Dead by Dawn)   \n",
       "2614      2614  South Park: Bigger, Longer and Uncut   \n",
       "1189      1189                      Army of Darkness   \n",
       "1213      1213                Dead Alive (Braindead)   \n",
       "\n",
       "                                       genres  \\\n",
       "18811           Comedy|Horror|Sci-Fi|Thriller   \n",
       "1233             Action|Comedy|Fantasy|Horror   \n",
       "2614                 Animation|Comedy|Musical   \n",
       "1189   Action|Adventure|Comedy|Fantasy|Horror   \n",
       "1213                    Comedy|Fantasy|Horror   \n",
       "\n",
       "                                               key  year  n_ratings  \\\n",
       "18811               Cabin in the Woods, The (2012)  2012       1757   \n",
       "1233            Evil Dead II (Dead by Dawn) (1987)  1987       7788   \n",
       "2614   South Park: Bigger, Longer and Uncut (1999)  1999      17371   \n",
       "1189                       Army of Darkness (1993)  1993      12469   \n",
       "1213                 Dead Alive (Braindead) (1992)  1992       2576   \n",
       "\n",
       "       mean_rating  predicted_rating  \n",
       "18811     3.677391          5.557927  \n",
       "1233      3.772888          5.304126  \n",
       "2614      3.626832          5.202612  \n",
       "1189      3.723536          5.187207  \n",
       "1213      3.727050          5.079445  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_nonobscure(model, uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Fixing our obscure recommendation problem (regularization)\n",
    "\n",
    "The code below is identical to the code used to create the model we've been using in this exercise, except we've added L2 regularization to our embeddings (by specifying a value for the keyword argument `embeddings_regularizer` when creating our Embedding layers).\n",
    "\n",
    "> **TODO: Aside here giving an introduction to regularization via weight penalty. Intuitive interpretation (imposing a prior), and mechanics of how it works (adding a term to the loss calculated as blah).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embedding_size = user_embedding_size = 8\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "l2_model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this model for a decent number of iterations takes around 15 minutes, so to save some time, I have an already trained model you can load from disk by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "l2_model = keras.models.load_model('movie_svd_model_8_r12n.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you're curious, you can check out the kernel where I trained this model [here](TODO). You may notice that, aside from whether the addition of regularization improves the subjective quality of our recommendations, it already has the benefit of improving our validation error, by reducing overfitting.)\n",
    "\n",
    "Try using the code you wrote in part 1 to generate recommendations using this model. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the recommend() function you wrote earlier to get the 5 best recommended movies\n",
    "# for user 26556, and assign them to the variable l2_reccs.\n",
    "l2_reccs = []\n",
    "#part5.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>228</td>\n",
       "      <td>Dumb &amp; Dumber (Dumb and Dumber)</td>\n",
       "      <td>Adventure|Comedy</td>\n",
       "      <td>Dumb &amp; Dumber (Dumb and Dumber) (1994)</td>\n",
       "      <td>1994</td>\n",
       "      <td>32085</td>\n",
       "      <td>2.950768</td>\n",
       "      <td>5.550111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1471</td>\n",
       "      <td>Austin Powers: International Man of Mystery</td>\n",
       "      <td>Action|Adventure|Comedy</td>\n",
       "      <td>Austin Powers: International Man of Mystery (1...</td>\n",
       "      <td>1997</td>\n",
       "      <td>22074</td>\n",
       "      <td>3.442133</td>\n",
       "      <td>5.316734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>340</td>\n",
       "      <td>Ace Ventura: Pet Detective</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Ace Ventura: Pet Detective (1994)</td>\n",
       "      <td>1994</td>\n",
       "      <td>38226</td>\n",
       "      <td>2.982501</td>\n",
       "      <td>5.267947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>1372</td>\n",
       "      <td>Beavis and Butt-Head Do America</td>\n",
       "      <td>Adventure|Animation|Comedy|Crime</td>\n",
       "      <td>Beavis and Butt-Head Do America (1996)</td>\n",
       "      <td>1996</td>\n",
       "      <td>8752</td>\n",
       "      <td>2.964548</td>\n",
       "      <td>5.233418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>2597</td>\n",
       "      <td>Austin Powers: The Spy Who Shagged Me</td>\n",
       "      <td>Action|Adventure|Comedy</td>\n",
       "      <td>Austin Powers: The Spy Who Shagged Me (1999)</td>\n",
       "      <td>1999</td>\n",
       "      <td>24651</td>\n",
       "      <td>3.213309</td>\n",
       "      <td>5.177351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                        title  \\\n",
       "228       228              Dumb & Dumber (Dumb and Dumber)   \n",
       "1471     1471  Austin Powers: International Man of Mystery   \n",
       "340       340                   Ace Ventura: Pet Detective   \n",
       "1372     1372              Beavis and Butt-Head Do America   \n",
       "2597     2597        Austin Powers: The Spy Who Shagged Me   \n",
       "\n",
       "                                genres  \\\n",
       "228                   Adventure|Comedy   \n",
       "1471           Action|Adventure|Comedy   \n",
       "340                             Comedy   \n",
       "1372  Adventure|Animation|Comedy|Crime   \n",
       "2597           Action|Adventure|Comedy   \n",
       "\n",
       "                                                    key  year  n_ratings  \\\n",
       "228              Dumb & Dumber (Dumb and Dumber) (1994)  1994      32085   \n",
       "1471  Austin Powers: International Man of Mystery (1...  1997      22074   \n",
       "340                   Ace Ventura: Pet Detective (1994)  1994      38226   \n",
       "1372             Beavis and Butt-Head Do America (1996)  1996       8752   \n",
       "2597       Austin Powers: The Spy Who Shagged Me (1999)  1999      24651   \n",
       "\n",
       "      mean_rating  predicted_rating  \n",
       "228      2.950768          5.550111  \n",
       "1471     3.442133          5.316734  \n",
       "340      2.982501          5.267947  \n",
       "1372     2.964548          5.233418  \n",
       "2597     3.213309          5.177351  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part5.solution()\n",
    "l2_reccs = recommend(l2_model, uid)\n",
    "l2_reccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think this model's predicted scores will look like for the 'obscure' movies that our earlier model highly recommended? Run the cell below to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>key</th>\n",
       "      <th>year</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>l2_predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21770</th>\n",
       "      <td>21770</td>\n",
       "      <td>McKenna Shoots for the Stars</td>\n",
       "      <td>Children|Drama</td>\n",
       "      <td>McKenna Shoots for the Stars (2012)</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>4.250</td>\n",
       "      <td>8.314224</td>\n",
       "      <td>3.516188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25793</th>\n",
       "      <td>25793</td>\n",
       "      <td>Babette Goes to War</td>\n",
       "      <td>Comedy|War</td>\n",
       "      <td>Babette Goes to War (1959)</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>7.968139</td>\n",
       "      <td>3.527213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25794</th>\n",
       "      <td>25794</td>\n",
       "      <td>Belle comme la femme d'un autre</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Belle comme la femme d'un autre (2014)</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.963304</td>\n",
       "      <td>3.523651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26329</th>\n",
       "      <td>26329</td>\n",
       "      <td>Sense &amp; Sensibility</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>Sense &amp; Sensibility (2008)</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>4.125</td>\n",
       "      <td>7.767611</td>\n",
       "      <td>3.521178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25823</th>\n",
       "      <td>25823</td>\n",
       "      <td>The Sex and Violence Family Hour</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>The Sex and Violence Family Hour (1983)</td>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>7.720166</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                             title              genres  \\\n",
       "21770    21770      McKenna Shoots for the Stars      Children|Drama   \n",
       "25793    25793               Babette Goes to War          Comedy|War   \n",
       "25794    25794   Belle comme la femme d'un autre              Comedy   \n",
       "26329    26329               Sense & Sensibility       Drama|Romance   \n",
       "25823    25823  The Sex and Violence Family Hour  (no genres listed)   \n",
       "\n",
       "                                           key  year  n_ratings  mean_rating  \\\n",
       "21770      McKenna Shoots for the Stars (2012)  2012          2        4.250   \n",
       "25793               Babette Goes to War (1959)  1959          1        1.500   \n",
       "25794   Belle comme la femme d'un autre (2014)  2014          1        1.000   \n",
       "26329               Sense & Sensibility (2008)  2008          4        4.125   \n",
       "25823  The Sex and Violence Family Hour (1983)  1983          1        1.500   \n",
       "\n",
       "       predicted_rating  l2_predicted_rating  \n",
       "21770          8.314224             3.516188  \n",
       "25793          7.968139             3.527213  \n",
       "25794          7.963304             3.523651  \n",
       "26329          7.767611             3.521178  \n",
       "25823          7.720166             3.517346  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = 26556\n",
    "obscure_reccs = recommend(model, uid)\n",
    "obscure_mids = obscure_reccs.index\n",
    "preds = l2_model.predict([\n",
    "    np.repeat(uid, len(obscure_mids)),\n",
    "    obscure_mids,\n",
    "])\n",
    "recc_df = movies_df.loc[obscure_mids].copy()\n",
    "recc_df['l2_predicted_rating'] = preds + offset\n",
    "recc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`</exercise>`\n",
    "\n",
    "# Scratch space below - please ignore\n",
    "\n",
    "```\n",
    "TODO\n",
    "- (maybe) look at dist. of weights of r12n model vs. prev model\n",
    "- (maybe) load another pretrained model with even stronger r12n. Compare reccs. What's the behaviour in the limit as we increase r12n strength?\n",
    "- Look at reccs for a few other users with fairly clear, distinctive tastes. e.g...\n",
    "    112287 (American Beauty, The Notebook, Mean Girls, The Devil Wears Prada)\n",
    "    69106 (Terminator 2, Toy Story, WALL-E, Days of Thunder, Star Wars, The Matrix)\n",
    "    83421 (The Godfather, The Shawshank Redemption, Casino, Casablanca)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 500\n",
    "movies_df[movies_df.n_ratings > thresh]\\\n",
    "    .sort_values(by='predicted_rating', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, = model.get_layer('movie_embedding').get_weights()\n",
    "\n",
    "w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, = model.get_layer('user_embedding').get_weights()\n",
    "\n",
    "w[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, = model.get_layer('movie_embedding').get_weights()\n",
    "wu, = model.get_layer('user_embedding').get_weights()\n",
    "\n",
    "print(\n",
    "    np.linalg.norm(wm[0]),\n",
    "    np.linalg.norm(wm[1]),\n",
    "    np.linalg.norm(wm[2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.linalg.norm(wm, axis=1)\n",
    "ns = pd.Series(norms)\n",
    "\n",
    "\n",
    "unorms = np.linalg.norm(wu, axis=1)\n",
    "nus = pd.Series(unorms)\n",
    "display(\n",
    "    \"Dist of movie norms:\",\n",
    "    ns.describe(),\n",
    "    \"Dist of user norms:\",\n",
    "    nus.describe(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "wm, = model.get_layer('movie_embedding').get_weights()\n",
    "wu, = model.get_layer('user_embedding').get_weights()\n",
    "\n",
    "quantiles = [.1, .25, .4, .5, .6, .75, .9]\n",
    "\n",
    "display(\n",
    "    \"Movie embedding weights:\",\n",
    "    pd.Series(wm.flatten()).describe(quantiles),\n",
    "    \"User embedding weights:\",\n",
    "    pd.Series(wu.flatten()).describe(quantiles),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "wm, = model.get_layer('movie_embedding').get_weights()\n",
    "wu, = model.get_layer('user_embedding').get_weights()\n",
    "bm, = model.get_layer('movie_bias').get_weights()\n",
    "bu, = model.get_layer('user_bias').get_weights()\n",
    "\n",
    "quantiles = [.1, .25, .4, .5, .6, .75, .9]\n",
    "\n",
    "display(\n",
    "    pd.Series(wm.flatten()).describe(quantiles),\n",
    "    pd.Series(wu.flatten()).describe(quantiles),\n",
    "    pd.Series(bm.flatten()).describe(quantiles),\n",
    "    pd.Series(bu.flatten()).describe(quantiles),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uggggh. Remember to do this before any training experiments.\n",
    "df = df.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: New experiment - dropout?\n",
    "movie_embedding_size = user_embedding_size = 32\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "dropout = .2\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "user_embedded = keras.layers.Dropout(dropout)(user_embedded)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "movie_embedded = keras.layers.Dropout(dropout)(movie_embedded)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")\n",
    "model.compile(\n",
    "    tf.train.AdamOptimizer(0.001),\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "\n",
    "tf.set_random_seed(1); np.random.seed(1); random.seed(1)\n",
    "history = model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=15,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('movie_svd_model_32_dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embedding_size = user_embedding_size = 32\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "#movie_r12n = user_r12n = None # zzz\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "biases = 0\n",
    "if biases:\n",
    "    bias_r12n = None\n",
    "    bias_r12n = keras.regularizers.l1_l2(l1=1e-4, l2=1e-7) # XXX 1e-6 -> 1e-4\n",
    "    bias_init = 'zeros'\n",
    "    movie_b = keras.layers.Embedding(df.movieId.max()+1, 1, \n",
    "                                             name='movie_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(movie_id_input)\n",
    "    movie_b = keras.layers.Flatten()(movie_b)\n",
    "    #out = keras.layers.Add()([movie_b, out])\n",
    "\n",
    "    user_b = keras.layers.Embedding(df.userId.max()+1, 1, \n",
    "                                             name='user_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(user_id_input)\n",
    "    user_b = keras.layers.Flatten()(user_b)\n",
    "    out = keras.layers.Add()([user_b, movie_b, out])\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")\n",
    "model.compile(\n",
    "    tf.train.AdamOptimizer(0.001), # XXX: Try lower?\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "#model.summary()\n",
    "\n",
    "tf.set_random_seed(1); np.random.seed(1); random.seed(1)\n",
    "history = model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embedding_size = user_embedding_size = 32\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "#movie_r12n = user_r12n = None # zzz\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "biases = 0\n",
    "if biases:\n",
    "    bias_r12n = None\n",
    "    bias_r12n = keras.regularizers.l1_l2(l1=1e-4, l2=1e-7) # XXX 1e-6 -> 1e-4\n",
    "    bias_init = 'zeros'\n",
    "    movie_b = keras.layers.Embedding(df.movieId.max()+1, 1, \n",
    "                                             name='movie_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(movie_id_input)\n",
    "    movie_b = keras.layers.Flatten()(movie_b)\n",
    "    #out = keras.layers.Add()([movie_b, out])\n",
    "\n",
    "    user_b = keras.layers.Embedding(df.userId.max()+1, 1, \n",
    "                                             name='user_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(user_id_input)\n",
    "    user_b = keras.layers.Flatten()(user_b)\n",
    "    out = keras.layers.Add()([user_b, movie_b, out])\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")\n",
    "model.compile(\n",
    "    tf.train.AdamOptimizer(0.001), # XXX: Try lower?\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "#model.summary()\n",
    "\n",
    "tf.set_random_seed(1); np.random.seed(1); random.seed(1)\n",
    "history = model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('movie_svd_model_8_r12n.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=8,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, this is excellent. Biases seem shockingly low. \n",
    "# I wonder if accuracy is much affected by just taking them away?\n",
    "# XXX: lower lr experiment\n",
    "movie_embedding_size = user_embedding_size = 16 # XXX: Tested with 8 (and worked well there). idk if \n",
    "# r12n might need to go up when increasing the number of parameters like this?\n",
    "\n",
    "# Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "movie_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-6)\n",
    "user_r12n = keras.regularizers.l1_l2(l1=0, l2=1e-7)\n",
    "#movie_r12n = user_r12n = None # zzz\n",
    "user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size,\n",
    "                                       embeddings_initializer='glorot_uniform',\n",
    "                                       embeddings_regularizer=user_r12n,\n",
    "                                       input_length=1, name='user_embedding')(user_id_input)\n",
    "movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                        embeddings_initializer='glorot_uniform',\n",
    "                                        embeddings_regularizer=movie_r12n,\n",
    "                                        input_length=1, name='movie_embedding')(movie_id_input)\n",
    "\n",
    "dotted = keras.layers.Dot(2)([user_embedded, movie_embedded])\n",
    "out = keras.layers.Flatten()(dotted)\n",
    "\n",
    "biases = 1\n",
    "if biases:\n",
    "    bias_r12n = None\n",
    "    bias_r12n = keras.regularizers.l1_l2(l1=1e-4, l2=1e-7) # XXX 1e-6 -> 1e-4\n",
    "    bias_init = 'zeros'\n",
    "    movie_b = keras.layers.Embedding(df.movieId.max()+1, 1, \n",
    "                                             name='movie_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(movie_id_input)\n",
    "    movie_b = keras.layers.Flatten()(movie_b)\n",
    "    #out = keras.layers.Add()([movie_b, out])\n",
    "\n",
    "    user_b = keras.layers.Embedding(df.userId.max()+1, 1, \n",
    "                                             name='user_bias',\n",
    "                                             embeddings_initializer=bias_init,\n",
    "                                             embeddings_regularizer=bias_r12n,\n",
    "                                            )(user_id_input)\n",
    "    user_b = keras.layers.Flatten()(user_b)\n",
    "    out = keras.layers.Add()([user_b, movie_b, out])\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [user_id_input, movie_id_input],\n",
    "    outputs = out,\n",
    ")\n",
    "model.compile(\n",
    "    tf.train.AdamOptimizer(0.001), # XXX: Try lower?\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "#model.summary()\n",
    "\n",
    "tf.set_random_seed(1); np.random.seed(1); random.seed(1)\n",
    "history = model.fit(\n",
    "    [df.userId, df.movieId],\n",
    "    df.y,\n",
    "    batch_size=10**4,\n",
    "    epochs=60,\n",
    "    verbose=2,\n",
    "    validation_split=.05,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('movie_svd_model_16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(preds.flatten()).describe([.05, .1, .25, .5, .75, .9, .95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These reccos suck. OTOH, this is a great motivator/lead-in to r12n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch space / brainstorm\n",
    "\n",
    "Idea: focus on r12n? (In the same way that I was thinking of having ex 1 be walking through adding biases step by step.)\n",
    "\n",
    "Are there other datasets I could have them do factorization on? (Could then be fun to use those learned embeddings for next two exercises)\n",
    "\n",
    "- million song dataset https://www.kaggle.com/c/msdchallenge\n",
    "- goodreads https://www.kaggle.com/zygmunt/goodbooks-10k/home <--- this one looks promising\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "This technique makes it easier to generate recommendations for a particular user. Let's try it. (I guess this is a point where having some understanding of the matrix factorization aspect would be useful.)\n",
    "\n",
    "To make recommendations for user u...\n",
    "- could individually calculate predicted scores for every movie in the dataset, but that'd be pretty tedious.\n",
    "- multiply user vector by weight matrix to get a column vector with predicted scores per movie. Sort.\n",
    "\n",
    "## convergence properties (thought experiment)\n",
    "\n",
    "Compare the loss over time of some DNN models like the ones we trained yesterday vs. some factorization models. Do you notice a difference? Can you think of why this would be?\n",
    "\n",
    "## factorization vs. dnn (thought experiment)\n",
    "\n",
    "We seem to be getting better results with our factorization model. But can you think of situations where you would want to use the dnn model instead?\n",
    "\n",
    "## r12n\n",
    "\n",
    "Look at train vs. val loss for different embedding sizes. How could we prevent overfitting while keeping a larger embedding size? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
