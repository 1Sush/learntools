{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "\n",
    "- Subset dataset to movies/users appearing at least n/m times\n",
    "- compactify movie ids\n",
    "- do train/test split?\n",
    "\n",
    "Output = new versions of...\n",
    "\n",
    "rating.csv. As before except\n",
    "- no timestamp column\n",
    "- use compactified movieIds\n",
    "- add val/train flag\n",
    "- add 'y' col (centred)\n",
    "- add 'yscaled' col\n",
    "\n",
    "movie.csv. As before except\n",
    "- new compactified movieIds\n",
    "- parse out base title and year into separate cols (keeping original as well - maybe as 'key' column)\n",
    "- nratings col\n",
    "- avg_rating col\n",
    "\n",
    "Also, some other file mapping between old and new movie ids (just in case that's useful later?)\n",
    "Or maybe just store in movie.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from functools import lru_cache\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack for running on kernels and locally\n",
    "RUNNING_ON_KERNELS = 'KAGGLE_WORKING_DIR' in os.environ\n",
    "input_dir = '../input' if RUNNING_ON_KERNELS else '../input/movies'\n",
    "out_dir = '.' if RUNNING_ON_KERNELS else '../input/movielens_preprocessed'\n",
    "\n",
    "rating_path = os.path.join(input_dir, 'rating.csv')\n",
    "df = pd.read_csv(rating_path, usecols=['userId', 'movieId', 'rating'])\n",
    "# Shuffle (reproducibly)\n",
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Partitioning train/val according to behaviour of keras.Model.fit() when called with\n",
    "# validation_split kwarg (which is to take validation data from the end as a contiguous\n",
    "# chunk)\n",
    "val_split = .05\n",
    "n_ratings = len(df)\n",
    "n_train = math.floor(n_ratings * (1-val_split))\n",
    "itrain = df.index[:n_train]\n",
    "ival = df.index[n_train:]\n",
    "\n",
    "# Compactify movie ids. \n",
    "movie_id_encoder = LabelEncoder()\n",
    "# XXX: Just fitting globally for simplicity. See movie_helpers.py for more 'principled'\n",
    "# approach. I don't think there's any realistically useful data leakage here though.\n",
    "#orig_movieIds = df['movieId']\n",
    "df['movieId'] = movie_id_encoder.fit_transform(df['movieId'])\n",
    "\n",
    "# Add centred target variable\n",
    "df['y'] = df['rating'] - df.loc[itrain, 'rating'].mean()\n",
    "\n",
    "SCALE = 0\n",
    "if SCALE:\n",
    "    # Add version of target variable scale to [0, 1]\n",
    "    yscaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    yscaler.fit(df.loc[itrain, 'rating'].values.reshape(-1, 1))\n",
    "    df['y_unit_scaled'] = yscaler.transform(df['rating'].values.reshape(-1, 1))\n",
    "\n",
    "path = os.path.join(out_dir, 'rating.csv')\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a 10% sample of ratings for exercises (with re-compactified movieIds, and mapping back to canonical movie ids)\n",
    "n_mini = 2 * 10**6\n",
    "df_mini = df.sort_values(by='userId').head(n_mini).copy()\n",
    "df_mini['movieId_orig'] = df.loc[df_mini.index, 'movieId']\n",
    "mini_encoder = LabelEncoder()\n",
    "df_mini['movieId'] = mini_encoder.fit_transform(df_mini['movieId'])\n",
    "# Shuffle\n",
    "df_mini = df_mini.sample(frac=1, random_state=1)\n",
    "\n",
    "# Recalculate y (just to be totally on the level. Very little opportunity for contamination here.)\n",
    "# Actually, the mean here turns out to be noticeably different (.05 higher). Probably because we're\n",
    "# Taking the front 10% after sorting by userId, and presumably userId ordering is actually informative\n",
    "# in some way (new users vs. old users?). More principled approach would be to take a subset of 10% of\n",
    "# userids. But then we'd have to compactify those... This is fine for now.\n",
    "n_mini_train = math.floor(n_mini * (1-val_split))\n",
    "mini_train_rating_mean = df_mini.iloc[:n_mini_train]['rating'].mean()\n",
    "df_mini['y'] = df_mini['rating'] - mini_train_rating_mean\n",
    "\n",
    "path = os.path.join(out_dir, 'mini_rating.csv')\n",
    "df_mini.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_title(title):\n",
    "    i = title.rfind(' (')\n",
    "    if i != -1:\n",
    "        title = title[:i]\n",
    "    for suff_word in ['The', 'A', 'An']:\n",
    "        suffix = ', {}'.format(suff_word)\n",
    "        if title.endswith(suffix):\n",
    "            title = suff_word + ' ' + title[:-len(suffix)]\n",
    "    return title\n",
    "\n",
    "def get_year(title):\n",
    "    l = title.rfind('(') + 1\n",
    "    try:\n",
    "        return int(title[l:l+4])\n",
    "    except ValueError:\n",
    "        print(title, end='\\t')\n",
    "        return 0\n",
    "\n",
    "movie_path = os.path.join(input_dir, 'movie.csv')\n",
    "movie_df = pd.read_csv(movie_path)\n",
    "mdf = movie_df\n",
    "\n",
    "# XXX: hack\n",
    "assert mdf.loc[\n",
    "    mdf.movieId==64997,\n",
    "    'title'].iloc[0] == 'War of the Worlds (2005)'\n",
    "mdf.loc[\n",
    "    mdf.movieId==64997,\n",
    "    'title'\n",
    "] = 'War of the Worlds (2005)x'\n",
    "\n",
    "#mdf['movieId_orig'] = mdf['movieId']\n",
    "n_orig = len(mdf)\n",
    "\n",
    "# There are some movies listed in movie.csv which have no ratings. Drop them.\n",
    "whitelist = set(movie_id_encoder.classes_)\n",
    "mdf = mdf[mdf['movieId'].isin(whitelist)].copy()\n",
    "print(\"Went from {} movies to {} after filtering out movies with no ratings\".format(\n",
    "    n_orig, len(mdf)\n",
    "))\n",
    "\n",
    "# New, compact movie Ids\n",
    "mdf['movieId'] = movie_id_encoder.transform(mdf['movieId'].values)\n",
    "\n",
    "mdf = mdf.sort_values(by='movieId').reset_index(drop=True)\n",
    "\n",
    "# By default use original title field (which includes year of release) as unique key\n",
    "mdf['key'] = mdf['title']\n",
    "\n",
    "mdf['year'] = mdf['title'].map(get_year)\n",
    "mdf['title'] = mdf['title'].map(munge_title)\n",
    "\n",
    "# For movies whose munged title are unique, use it as their key\n",
    "title_counts = mdf.groupby('title').size()\n",
    "unique_titles = title_counts.index[title_counts == 1]\n",
    "unique_ids = mdf.index[mdf.title.isin(unique_titles)]\n",
    "mdf.loc[unique_ids, 'key'] = mdf.loc[unique_ids, 'title']\n",
    "\n",
    "mdf['n_ratings'] = df.groupby('movieId').size()\n",
    "# NB: Calculated only over training set. (Though maybe this should be consistent with n_ratings)\n",
    "mean_ratings = df.loc[itrain].groupby('movieId')['rating'].mean()\n",
    "mdf['mean_rating'] = mean_ratings\n",
    "\n",
    "path = os.path.join(out_dir, 'movie.csv')\n",
    "mdf.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nvm, I don't think this is necessary.\n",
    "if 0:\n",
    "    popularity_thresh = 1000\n",
    "\n",
    "    popular = mdf[mdf['n_ratings'] >= popularity_thresh]\n",
    "\n",
    "    pop_ratings = df[df['movieId'].isin(popular.index)].copy()\n",
    "\n",
    "    print(\"Went from {:,} ratings to {:,} after applying threshold of {} ratings per movie\".format(\n",
    "        len(df), len(pop_ratings), popularity_thresh\n",
    "    ))\n",
    "\n",
    "    path = os.path.join(out_dir, 'mainstream_rating.csv')\n",
    "    pop_ratings.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "learntools_metadata": {
   "lesson_index": -1,
   "type": "tutorial"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
