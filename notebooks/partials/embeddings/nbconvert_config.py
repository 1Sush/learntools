"""
lessons_meta: list of lesson dicts

lesson has fields:
    topic: str
    exercise: notebook dict
    tutorial: notebook dict

notebook has fields (* = optional):
    scriptid: kaggle numerical kernel identifier thing
    slug: e.g. 'colinmorris/hello-python'. Autogenerated from title.
    title: e.g. 'Underwater Basketweaving'. If not specified, default to capitalized 
        lesson topic.
    filename: the name of the corresponding ipynb file (which should be in current directory)
    *kernel_sources: list of kernel slugs (as in kernel-metadata.json)
    *dataset_sources: list of dataset slugs (as in kernel-metadata.json)

scriptid is used in macro expansion to generate forking links (and so it's okay to use a
a placeholder to get started). topic and slug are also used in macro expansion.

slug, title, and filename are used in generating kernel metadata files for the kernels API
(see prepare_push.py)

TODO: would be nice to encapsulate the code surrounding:
    - represention of a lesson (this abstraction is currently only useful for
      the purposes of macro expansion)
    - represention of a nb
    - validating fields of above objs and filling in default vals
    - making a kernel-metadata.json file for a nb
Currently spread around nbconvert_config.py, lesson_preprocessor.py (cf. Lesson class)
and prepare_push.py, with some redundancy / awkward coupling points.

Crazy idea: have lesson/nb metadata (currently stored in lessons_meta list) live
in ipynb metadata (currently we're storing lesson index and tut/ex type there). I think this
could address some of the awkwardness around the current scheme, namely:
- sys.path hacking in prepare_push.py
- if __name__ == 'builtins' in this module
- filename munging in clean.py
- inexplicable traitlet stuff in LearnLessonPreprocessor (I don't think I understood
  what that code was doing even back when I first wrote it)

What would this new process look like?
1. Have some py file per track responsible just for storing canonical track metadata, per lesson/nb.
2. Have a step that syncs the metadata stored there to the corresponding ipynb files. 
  (join happens based on filename munging, or by explicitly encoding ipynb filename
  in the metadata in 1.) Perhaps along lines of current clean.py.
3. For all other purposes (nbconvert, prepare_push.py) the ipynb metadata is where
    they read the track metadata from (vs. nbconvert_config.lessons_meta now)
"""

PREFIX_TITLES = True

# (Cribbed from ../python. With some updates and documentation above.)
lessons_meta = [
        # NB: Kind of an ugly ouroboros bootstrapping process here where we need some version of this
        # metadata (with placeholder scriptids/slugs) in order to push initial kernel versions, which
        # then lets us update this with the actual scriptids/slugs.
        dict(topic='embedding layers',
            exercise=dict(
                scriptid=1,
                ),
            tutorial=dict(
                filename='1-embeddings.ipynb',
                ),
            ),

        dict(topic='matrix factorization',
            exercise=dict(
                scriptid=1,
                ),
            tutorial=dict(
                filename='2-factorization.ipynb',
                ),
            ),
        
        dict(topic='exploring embeddings with gensim',
            exercise=dict(
                scriptid=1,
                ),
            tutorial=dict(
                filename='3-gensim.ipynb',
                ),
            ),
        
        dict(topic='visualizing embeddings with t-SNE',
            exercise=dict(
                scriptid=1,
                ),
            tutorial=dict(
                filename='4-tsne.ipynb',
                ),
            ),
        
]

def slugify(title):
    s = title.replace('(', '').replace(')', '').replace(',', '').replace(':', '').lower()
    tokens = s.split()
    return '-'.join(tokens)

for i, lesson in enumerate(lessons_meta):
    num = i + 1
    lesson['exercise']['filename'] = '{}-exercises.ipynb'.format(num)
    #lesson['tutorial']['filename'] = 'tut_{}.ipynb'.format(num)
    ex = lesson['exercise']
    tut = lesson['tutorial']
    assert 'filename' in tut
    nbs = [ex, tut]
    assert not any('kernel_sources' in nb for nb in nbs)
    for nb in nbs:
        nb['kernel_sources'] = ['colinmorris/0-movielens-preprocessing']
    if 'title' not in tut:
        tut['title'] = lesson['topic'].capitalize()
    if PREFIX_TITLES:
        tut['title'] = '{} {}'.format(num, tut['title'])
    if 'title' not in ex:
        ex['title'] = 'Exercise: {}'.format(tut['title'])
    for thing in nbs:
        thing['slug'] = 'colinmorris/' + slugify(thing['title'])

# Encode some inter-notebook data dependencies. 
# NB: Once again there's a bootstrapping problem here. Probably dangerous when
# we're pushing version 1s of kernels (though safe if pushed in order?)
_nice_model_slug = 'colinmorris/x3-movielens-spiffy-model'
inter_notebook_deps = [
        # (A, B) -> A has a data dependency on B
        # Where A looks like:
        #   (lesson_num starting from 1, type in 'tutorial', 'exercise')
        # And B either has the same format (if it's a tutorial/exercise), or
        # is a string slug (if it's an ancilliary nb)
        [ (2, 'tutorial'), (1, 'tutorial') ],
        [ (2, 'exercise'), (2, 'tutorial') ],
        [ (4, 'exercise'), (4, 'tutorial') ],
        [ (2, 'exercise'), 'colinmorris/x2-movielens-factorization-r12n' ],
        [ (3, 'tutorial'), _nice_model_slug ],
        [ (3, 'exercise'), _nice_model_slug ],
        [ (4, 'tutorial'), _nice_model_slug ],
]
def _lookup_nb_tuple(tup):
    n, tag = tup
    i = n - 1
    return lessons_meta[i][tag]
for (dest, src) in inter_notebook_deps:
    dest_nb = _lookup_nb_tuple(dest)
    if isinstance(src, str):
        slug = src
    else:
        src_nb = _lookup_nb_tuple(src)
        slug = src_nb['slug']
    k_srcs = dest_nb.setdefault('kernel_sources', [])
    k_srcs.append(slug)

# Haaaaack.
if __name__ == 'builtins':
    c = get_config()

    # XXX: I forget what this signifies?
    c.NbConvertApp.notebooks = ['*.ipynb']
    #c.Exporter.preprocessors = ['lesson_preprocessor.LearnLessonPreprocessor']
    c.Exporter.preprocessors = ['embeddings_lesson_preprocessor.EmbeddingsLessonPreprocessor']

    #c.LearnLessonPreprocessor.lessons_metadata = lessons_meta
    c.EmbeddingsLessonPreprocessor.lessons_metadata = lessons_meta
